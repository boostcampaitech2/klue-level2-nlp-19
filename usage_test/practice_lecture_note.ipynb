{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e424a2",
   "metadata": {},
   "source": [
    "## train.csv 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68614e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...</td>\n",
       "      <td>{'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>{'word': '민주평화당', 'start_idx': 19, 'end_idx': ...</td>\n",
       "      <td>{'word': '대안신당', 'start_idx': 14, 'end_idx': 1...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>{'word': '광주FC', 'start_idx': 21, 'end_idx': 2...</td>\n",
       "      <td>{'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx...</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...</td>\n",
       "      <td>{'word': '아성다이소', 'start_idx': 13, 'end_idx': ...</td>\n",
       "      <td>{'word': '박정부', 'start_idx': 22, 'end_idx': 24...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...</td>\n",
       "      <td>{'word': '요미우리 자이언츠', 'start_idx': 22, 'end_id...</td>\n",
       "      <td>{'word': '1967', 'start_idx': 0, 'end_idx': 3,...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32465</th>\n",
       "      <td>32465</td>\n",
       "      <td>한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...</td>\n",
       "      <td>{'word': '유기준', 'start_idx': 93, 'end_idx': 95...</td>\n",
       "      <td>{'word': '부산 서구·동구', 'start_idx': 100, 'end_id...</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32466</th>\n",
       "      <td>32466</td>\n",
       "      <td>법포는 다시 최시형, 서병학, 손병희 직계인 북접과 다시 서장옥, 전봉준, 김개남을...</td>\n",
       "      <td>{'word': '최시형', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>{'word': '손병희', 'start_idx': 17, 'end_idx': 19...</td>\n",
       "      <td>per:colleagues</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32467</th>\n",
       "      <td>32467</td>\n",
       "      <td>완도군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 ...</td>\n",
       "      <td>{'word': '완도군', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '신우철', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32468</th>\n",
       "      <td>32468</td>\n",
       "      <td>중앙일보, JTBC 회장을 지낸 이후 중앙홀딩스 회장, 재단법인 한반도평화만들기 이...</td>\n",
       "      <td>{'word': 'JTBC', 'start_idx': 6, 'end_idx': 9,...</td>\n",
       "      <td>{'word': '중앙홀딩스', 'start_idx': 21, 'end_idx': ...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32469</th>\n",
       "      <td>32469</td>\n",
       "      <td>화순군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버...</td>\n",
       "      <td>{'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32470 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence  \\\n",
       "0          0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...   \n",
       "1          1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...   \n",
       "2          2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...   \n",
       "3          3  균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...   \n",
       "4          4  1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...   \n",
       "...      ...                                                ...   \n",
       "32465  32465  한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...   \n",
       "32466  32466  법포는 다시 최시형, 서병학, 손병희 직계인 북접과 다시 서장옥, 전봉준, 김개남을...   \n",
       "32467  32467  완도군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 ...   \n",
       "32468  32468  중앙일보, JTBC 회장을 지낸 이후 중앙홀딩스 회장, 재단법인 한반도평화만들기 이...   \n",
       "32469  32469  화순군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버...   \n",
       "\n",
       "                                          subject_entity  \\\n",
       "0      {'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...   \n",
       "1      {'word': '민주평화당', 'start_idx': 19, 'end_idx': ...   \n",
       "2      {'word': '광주FC', 'start_idx': 21, 'end_idx': 2...   \n",
       "3      {'word': '아성다이소', 'start_idx': 13, 'end_idx': ...   \n",
       "4      {'word': '요미우리 자이언츠', 'start_idx': 22, 'end_id...   \n",
       "...                                                  ...   \n",
       "32465  {'word': '유기준', 'start_idx': 93, 'end_idx': 95...   \n",
       "32466  {'word': '최시형', 'start_idx': 7, 'end_idx': 9, ...   \n",
       "32467  {'word': '완도군', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "32468  {'word': 'JTBC', 'start_idx': 6, 'end_idx': 9,...   \n",
       "32469  {'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "\n",
       "                                           object_entity  \\\n",
       "0      {'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...   \n",
       "1      {'word': '대안신당', 'start_idx': 14, 'end_idx': 1...   \n",
       "2      {'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx...   \n",
       "3      {'word': '박정부', 'start_idx': 22, 'end_idx': 24...   \n",
       "4      {'word': '1967', 'start_idx': 0, 'end_idx': 3,...   \n",
       "...                                                  ...   \n",
       "32465  {'word': '부산 서구·동구', 'start_idx': 100, 'end_id...   \n",
       "32466  {'word': '손병희', 'start_idx': 17, 'end_idx': 19...   \n",
       "32467  {'word': '신우철', 'start_idx': 7, 'end_idx': 9, ...   \n",
       "32468  {'word': '중앙홀딩스', 'start_idx': 21, 'end_idx': ...   \n",
       "32469  {'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...   \n",
       "\n",
       "                           label     source  \n",
       "0                    no_relation  wikipedia  \n",
       "1                    no_relation   wikitree  \n",
       "2                  org:member_of   wikitree  \n",
       "3      org:top_members/employees   wikitree  \n",
       "4                    no_relation  wikipedia  \n",
       "...                          ...        ...  \n",
       "32465            per:employee_of   wikitree  \n",
       "32466             per:colleagues  wikipedia  \n",
       "32467  org:top_members/employees   wikitree  \n",
       "32468                no_relation  wikipedia  \n",
       "32469  org:top_members/employees   wikitree  \n",
       "\n",
       "[32470 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "total_df = pd.read_csv(\"/opt/ml/dataset/train/train.csv\")\n",
    "total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b024c058",
   "metadata": {},
   "source": [
    "## Column 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289ea2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>광주FC</td>\n",
       "      <td>한국프로축구연맹</td>\n",
       "      <td>org:member_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...</td>\n",
       "      <td>아성다이소</td>\n",
       "      <td>박정부</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...</td>\n",
       "      <td>요미우리 자이언츠</td>\n",
       "      <td>1967</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32465</th>\n",
       "      <td>32465</td>\n",
       "      <td>한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...</td>\n",
       "      <td>유기준</td>\n",
       "      <td>부산 서구·동구</td>\n",
       "      <td>per:employee_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32466</th>\n",
       "      <td>32466</td>\n",
       "      <td>법포는 다시 최시형, 서병학, 손병희 직계인 북접과 다시 서장옥, 전봉준, 김개남을...</td>\n",
       "      <td>최시형</td>\n",
       "      <td>손병희</td>\n",
       "      <td>per:colleagues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32467</th>\n",
       "      <td>32467</td>\n",
       "      <td>완도군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 ...</td>\n",
       "      <td>완도군</td>\n",
       "      <td>신우철</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32468</th>\n",
       "      <td>32468</td>\n",
       "      <td>중앙일보, JTBC 회장을 지낸 이후 중앙홀딩스 회장, 재단법인 한반도평화만들기 이...</td>\n",
       "      <td>JTBC</td>\n",
       "      <td>중앙홀딩스</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32469</th>\n",
       "      <td>32469</td>\n",
       "      <td>화순군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버...</td>\n",
       "      <td>화순군</td>\n",
       "      <td>구충곤</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32470 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence  \\\n",
       "0          0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...   \n",
       "1          1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...   \n",
       "2          2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...   \n",
       "3          3  균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...   \n",
       "4          4  1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...   \n",
       "...      ...                                                ...   \n",
       "32465  32465  한국당은 7일 오전 9시부터 오후 5시까지 진행된 원내대표 및 정책위의장 후보자 등...   \n",
       "32466  32466  법포는 다시 최시형, 서병학, 손병희 직계인 북접과 다시 서장옥, 전봉준, 김개남을...   \n",
       "32467  32467  완도군(군수 신우철)이 국토교통부에서 실시한 '2019 교통문화지수 실태조사'에서 ...   \n",
       "32468  32468  중앙일보, JTBC 회장을 지낸 이후 중앙홀딩스 회장, 재단법인 한반도평화만들기 이...   \n",
       "32469  32469  화순군(군수 구충곤)은 17일 동면의 이장 20여 명이 코로나 19 예방을 위해 버...   \n",
       "\n",
       "      subject_entity object_entity                      label  \n",
       "0                비틀즈        조지 해리슨                no_relation  \n",
       "1              민주평화당          대안신당                no_relation  \n",
       "2               광주FC      한국프로축구연맹              org:member_of  \n",
       "3              아성다이소           박정부  org:top_members/employees  \n",
       "4          요미우리 자이언츠          1967                no_relation  \n",
       "...              ...           ...                        ...  \n",
       "32465            유기준      부산 서구·동구            per:employee_of  \n",
       "32466            최시형           손병희             per:colleagues  \n",
       "32467            완도군           신우철  org:top_members/employees  \n",
       "32468           JTBC         중앙홀딩스                no_relation  \n",
       "32469            화순군           구충곤  org:top_members/employees  \n",
       "\n",
       "[32470 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_entity = []\n",
    "object_entity = []\n",
    "for i,j in zip(total_df['subject_entity'], total_df['object_entity']):\n",
    "    i = eval(i)['word']\n",
    "    j = eval(j)['word']\n",
    "\n",
    "    subject_entity.append(i)\n",
    "    object_entity.append(j)\n",
    "out_dataset = pd.DataFrame({'id':total_df['id'], 'sentence':total_df['sentence'],'subject_entity':subject_entity,'object_entity':object_entity,'label':total_df['label'],})\n",
    "out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf1b8df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null 제거 후 학습 데이터셋 : 32470\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "out_dataset['sentence'].replace('', np.nan, inplace=True)\n",
    "out_dataset = out_dataset.dropna(how = 'any')\n",
    "print('null 제거 후 학습 데이터셋 : {}'.format(len(out_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51ac78",
   "metadata": {},
   "source": [
    "## Mecab 사용 - 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c159087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('〈', 'SY'), ('Something', 'SL'), ('〉', 'SY'), ('는', 'JX'), ('조지', 'NNP'), ('해리슨', 'NNP'), ('이', 'JKS'), ('쓰', 'VV'), ('고', 'EC'), ('비틀즈', 'NNP'), ('가', 'JKS'), ('1969', 'SN'), ('년', 'NNBC'), ('앨범', 'NNG'), ('《', 'SY'), ('Abbey', 'SL'), ('Road', 'SL'), ('》', 'SY'), ('에', 'JKB'), ('담', 'VV'), ('은', 'ETM'), ('노래', 'NNG'), ('다', 'VCP+EF'), ('.', 'SF')]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "morphs = mecab.pos(out_dataset['sentence'][0], join=False)\n",
    "print(morphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae7db7",
   "metadata": {},
   "source": [
    "## Mecab 사용 - 문장 판단하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e800ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_filter(texts):\n",
    "    \"\"\"\n",
    "    명사(NN), 동사(V), 형용사(J)의 포함 여부에 따라 문장 필터링\n",
    "    \"\"\"\n",
    "    NN_TAGS = [\"NNG\", \"NNP\", \"NNB\", \"NP\"]\n",
    "    V_TAGS = [\"VV\", \"VA\", \"VX\", \"VCP\", \"VCN\", \"XSN\", \"XSA\", \"XSV\"]\n",
    "    J_TAGS = [\"JKS\", \"J\", \"JO\", \"JK\", \"JKC\", \"JKG\", \"JKB\", \"JKV\", \"JKQ\", \"JX\", \"JC\", \"JKI\", \"JKO\", \"JKM\", \"ETM\"]\n",
    "\n",
    "    preprocessed_text = {}\n",
    "    not_sentence = {}\n",
    "    for idx, text in enumerate(texts):\n",
    "        morphs = mecab.pos(text, join=False)\n",
    "        \n",
    "        nn_flag = False\n",
    "        v_flag = False\n",
    "        j_flag = False\n",
    "        for morph in morphs:\n",
    "            pos_tags = morph[1].split(\"+\")\n",
    "            for pos_tag in pos_tags:\n",
    "                if not nn_flag and pos_tag in NN_TAGS:\n",
    "                    nn_flag = True\n",
    "                if not v_flag and pos_tag in V_TAGS:\n",
    "                    v_flag = True\n",
    "                if not j_flag and pos_tag in J_TAGS:\n",
    "                    j_flag = True\n",
    "            if nn_flag and v_flag and j_flag:\n",
    "                preprocessed_text[idx] = text\n",
    "                break\n",
    "        if not(nn_flag and v_flag and j_flag):\n",
    "            not_sentence[idx] = text\n",
    "    return preprocessed_text, not_sentence\n",
    "\n",
    "_, not_sentence = morph_filter(out_dataset['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7a98f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 유엔, 유럽 의회, 북대서양 조약 기구 (NATO), 국제이주기구, 세계 보건 기구 (WHO), 지중해 연합, 이슬람 협력 기구, 유럽 안보 협력 기구, 국제 통화 기금, 세계무역기구 그리고 프랑코포니. | 북대서양 조약 기구 | NATO | org:alternate_names\n",
      "354 CJ그룹 이재현 회장이다. | CJ그룹 | 이재현 | org:top_members/employees\n",
      "1049 시가총액 상위주 역시 삼성전자(1.41%), SK하이닉스(1.24%), 현대차(0.38%), NAVER(1.07%), 현대모비스(0.85%), LG화학(0.79%), 셀트리온(0.97%), 신한지주(0.49%), SK텔레콤(0.62%) 모두 올랐다. | SK하이닉스 | SK텔레콤 | no_relation\n",
      "1130 박주호 선수 소속팀 울산 현대 유니폼이다. | 박주호 | 울산 현대 | per:employee_of\n",
      "1260 1979년 10월 26일 박정희 사후 야당화되었으며 1980년 10월 27일 해산되었다. | 박정희 | 1979년 10월 26일 | per:date_of_death\n",
      "2654 1986년 김건우 선수, 1988년 이용철 선수, 1990년 김동수 선수, 1994년 유지현 선수, 1997년 이병규 선수, 2019년 정우영 선수다. | 김건우 | 1986년 | no_relation\n",
      "4458 뿌요뿌요의 제작자는 컴파일 대표 니이타니 마사미츠(仁井谷正充). | 컴파일 | 뿌요뿌요 | org:product\n",
      "4657 후쿠오카 소프트뱅크 호크스 주식회사 대표이사 회장 겸 단장, 일본 프로 야구 명구회 고문이다. | 소프트뱅크 | 주식회사 | no_relation\n",
      "5069 콜롬비아 축구선수 안드레스 에스코바르(Andrés Escobar) 이야기다. | 안드레스 에스코바르 | 콜롬비아 | per:origin\n",
      "5263 전 퍼시픽 리그 후쿠오카 소프트뱅크 호크스 2군 타격 코치였다. | 후쿠오카 소프트뱅크 호크스 | 퍼시픽 리그 | org:member_of\n",
      "5818 서울대학교 8회(9, 10, 14, 25, 26, 27, 30, 32회) 한국예술종합학교 6회(15, 16, 19, 20, 21, 33회), 중앙대학교 5회(4, 12, 18, 22, 29회), 한양대학교 3회(3, 23, 31회), 전북대학교 2회(17, 28회), 단국대학교 1회(8회), 서울예술대학교 1회(11회), 추계예술대학교 1회(2회), 이화여자대학교 1회(13회). | 학교 2 | 학교 3 | no_relation\n",
      "6010 뿌요뿌요의 제작자는 컴파일 대표 니이타니 마사미츠(仁井谷正充). | 컴파일 | 니이타니 마사미츠 | org:top_members/employees\n",
      "6053 KIA 중견수 이대형 (101.21%) 등이다. | 이대형 | 중견수 | per:title\n",
      "6114 우치다 마아야 (内田真礼, 1989년 12월 27일 -)는 일본의 성우, 여배우, 가수. | 우치다 마아야 | 1989년 12월 27일 | per:date_of_birth\n",
      "6610 마키노 마리아(2001년 2월 2일 ~)는 일본의 여성 아이돌 그룹 모닝구무스메의 멤버. 연예사무소 업프런트 프로모션 소속. 아이치현 출신. | 마키노 마리아 | 2001년 2월 2일 | per:date_of_birth\n",
      "8496 Dahlberg, Ingetraut (2010) 국제지식조직학회 (ISKO), \"문헌정보학 백과사전, 제3판\", 1 : 1, 2941 - 2949. | 국제지식조직학회 | ISKO | org:alternate_names\n",
      "9717 쿠로사와 토모요 (黒沢ともよ, 1996년 4월 10일 -)는 일본의 여배우, 성우, 가수. 마우스 프로모션 소속. 사이타마현 출신. | 쿠로사와 토모요 | 1996년 4월 10일 | per:date_of_birth\n",
      "10070 1984년 10월 (주)광주고속이 금호건설(주)를 합병. (주)광주고속이 건설사업에 진출. | 광주고속 | 금호건설 | org:members\n",
      "11869 쿠틉 앗딘 마우두드 (1170년 9월 6일 죽음)는 장기 왕조의 군주 중 한명으로, 1149년부터 1169년까지 모술을 지배했다. | 쿠틉 앗딘 마우두드 | 1170년 9월 6일 | per:date_of_death\n",
      "12008 일레븐, 마이크 휠러, 루카스 싱클레어, 더스틴 헨더슨, 윌 바이어스, 조이스 바이어스, 짐 호퍼 서장, 데모고르곤이다. | 짐 호퍼 | 일레븐 | no_relation\n",
      "12534 니코스 카잔차키스 (1885-1957)는 그리스 시인·소설가. | 니코스 카잔차키스 | 그리스 | per:origin\n",
      "14025 시가총액 상위주 역시 삼성전자(-0.46%), SK하이닉스(-0.27%), 현대차(-1.15%), NAVER(-0.36%), 현대모비스(-1.05%), LG화학(-0.48%), 셀트리온(-1.61%), SK텔레콤(-0.41%), 신한지주(-0.61%) 모두 약세다. | SK하이닉스 | SK텔레콤 | no_relation\n",
      "15679 배드민턴 스타 이용대(31) 선수 2020 도쿄 올림픽행이 무산됐다. | 이용대 | 배드민턴 | no_relation\n",
      "15709 시가총액 상위주 역시 삼성전자(-0.8%), SK하이닉스(-3.49%), 현대차(-1.19%), NAVER(-3.37%), LG화학(-1.82%), 현대모비스(-1.04%), SK텔레콤(-0.63%), 신한지주(-1.61%), 셀트리온(-6.60%) 모두 내렸다. | 하이닉스 | SK텔레콤 | no_relation\n",
      "15795 필라델피아 시청 167m(548ft) 및 Anton Antoniana 167.5m(550ft)이다. | 필라델피아 시청 | 167m | no_relation\n",
      "17702 김문오 대구 달성군수였다. | 김문오 | 대구 달성군수 | per:title\n",
      "18397 마키노 마리아(2001년 2월 2일 ~)는 일본의 여성 아이돌 그룹 모닝구무스메의 멤버. 연예사무소 업프런트 프로모션 소속. 아이치현 출신. | 마키노 마리아 | 업프런트 프로모션 | per:employee_of\n",
      "19596 삼성 중견수 박해민 (103.26%) 등이다. | 박해민 | 중견수 | per:title\n",
      "20689 마키하라 노리유키(1969년 5월 18일 ~)는 일본의 싱어송라이터이자 작곡가, 작사가. | 마키하라 노리유키 | 싱어송라이터 | per:title\n",
      "21299 FC 스파르타크 모스크바, PFC CSKA 모스크바, FC 디나모 모스크바, FC 로코모티프 모스크바, FC 토르페도 모스크바. | FC 디나모 모스크바 | FC 로코모티프 모스크바 | no_relation\n",
      "22725 704(칠백사, DCCIV, 2C0) = 2×11. | 칠백사 | DCC | no_relation\n",
      "27260 바로 배우 정시아(박현정·38) 딸 백서우(7) 양이다. | 정시아 | 박현정 | per:alternate_names\n",
      "28864 점프스퀘어(슈에이샤)에서 2012년부터 발간 중. | 점프스퀘어 | 슈에이샤 | no_relation\n",
      "29071 764(칠백육십사, DCCLXIV, 2FC) = 2×191. | 칠백육십사 | DCC | no_relation\n",
      "29374 시가총액 상위주 역시 삼성전자(-0.8%), SK하이닉스(-3.49%), 현대차(-1.19%), NAVER(-3.37%), LG화학(-1.82%), 현대모비스(-1.04%), SK텔레콤(-0.63%), 신한지주(-1.61%), 셀트리온(-6.60%) 모두 내렸다. | SK하이닉스 | SK텔레콤 | no_relation\n"
     ]
    }
   ],
   "source": [
    "for i, sent in not_sentence.items():\n",
    "    print(i, sent,\"|\", out_dataset['subject_entity'][i],\"|\", out_dataset['object_entity'][i],\"|\", out_dataset['label'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a367c",
   "metadata": {},
   "source": [
    "## WordPiece tokenizing 학습 전과 학습 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc42c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "mkdir: cannot create directory 'wordPieceTokenizer': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir wordPieceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94cb3d",
   "metadata": {},
   "source": [
    "### 학습 전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a8c9bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# Initialize an empty tokenizer\n",
    "wp_tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,    # [이순신, ##은, ' ', 조선]\n",
    "    handle_chinese_chars=True,\n",
    "    strip_accents=False,    # True: [YepHamza] -> [Yep, Hamza]\n",
    "    lowercase=False,\n",
    ")\n",
    "\n",
    "print(wp_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d40cd57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizers.implementations.bert_wordpiece.BertWordPieceTokenizer"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wp_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8ef23",
   "metadata": {},
   "source": [
    "### 학습 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc875c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['wordPieceTokenizer/my_tokenizer_1sen-vocab.txt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then train\n",
    "wp_tokenizer.train(\n",
    "    files=\"/opt/ml/klue-level2-nlp-19/resources/wiki_20190620_small.txt\",\n",
    "    vocab_size=100000,  #? limit vocab_size\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
    "    limit_alphabet=1000,\n",
    "    wordpieces_prefix=\"##\"  #? 단어조각으로 판단할 경우 앞에 ##를 붙인다.\n",
    ")\n",
    "\n",
    "# Save the files\n",
    "wp_tokenizer.save_model(\"wordPieceTokenizer\", \"my_tokenizer_1sen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ac3475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25717\n",
      "Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['이', '##순', '##신은', '조선', '중', '##기의', '무신', '##이다', '.']\n",
      "[706, 1319, 7606, 2001, 754, 2605, 13161, 1896, 16]\n"
     ]
    }
   ],
   "source": [
    "print(wp_tokenizer.get_vocab_size())\n",
    "text = \"이순신은 조선 중기의 무신이다.\"\n",
    "tokenized_text = wp_tokenizer.encode(text)\n",
    "print(tokenized_text)\n",
    "print(tokenized_text.tokens)\n",
    "print(tokenized_text.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8355f4",
   "metadata": {},
   "source": [
    "### 학습 결과 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "620cc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\"./wordPieceTokenizer/my_tokenizer_1sen-vocab.txt\", lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b3a68119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['이', '##순', '##신은', '조선', '중', '##기의', '무신', '##이다', '.']\n",
      "[706, 1319, 7606, 2001, 754, 2605, 13161, 1896, 16]\n"
     ]
    }
   ],
   "source": [
    "text = \"이순신은 조선 중기의 무신이다.\"\n",
    "tokenized_text = wp_tokenizer.encode(text)\n",
    "print(tokenized_text)\n",
    "print(tokenized_text.tokens)\n",
    "print(tokenized_text.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "08dc20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "33a73dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_sentences = tokenizer(\n",
    "    text,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "00ea3899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 10661,  2073,  3957,  9652,  2079, 15749, 28674,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a2e83",
   "metadata": {},
   "source": [
    "### tokenizer 함수 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9cf9a793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이순신', '##은', '조선', '중기', '##의', '무신', '##이다', '.']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "981e7081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 10661, 2073, 3957, 9652, 2079, 15749, 28674, 18, 3]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c0f88e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10661, 2073, 3957, 9652, 2079]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\n",
    "    text,\n",
    "    add_special_tokens=False,\n",
    "    max_length=5,\n",
    "    truncation=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6d6fb442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb3d171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'that': 16845,\n",
       " '고즈': 30514,\n",
       " '사진': 4035,\n",
       " '현대건설': 15691,\n",
       " '=': 33,\n",
       " '안산시': 17233,\n",
       " '이조': 25227,\n",
       " '레이': 5395,\n",
       " '경정': 16367,\n",
       " '모터': 8247,\n",
       " '빠': 1196,\n",
       " '고의': 11242,\n",
       " '##89': 22934,\n",
       " '그것': 3724,\n",
       " '나선': 5120,\n",
       " '직능': 29313,\n",
       " '증빙': 21875,\n",
       " '한단': 13855,\n",
       " '형주': 29443,\n",
       " '[unused318]': 31818,\n",
       " '1909': 25816,\n",
       " '입대': 12119,\n",
       " '##시네마': 27717,\n",
       " '회계사': 24670,\n",
       " '보안': 6041,\n",
       " '뿌렸': 22637,\n",
       " '한창': 7880,\n",
       " '원주': 7216,\n",
       " '마모': 25723,\n",
       " '개막식': 13936,\n",
       " '맞은편': 14458,\n",
       " '담요': 20931,\n",
       " '장량': 26886,\n",
       " '값싼': 19793,\n",
       " '南': 270,\n",
       " '차감': 24647,\n",
       " '혈전': 24591,\n",
       " '서슴없이': 30215,\n",
       " '부단': 19202,\n",
       " '덤핑': 29171,\n",
       " '강석': 22982,\n",
       " '##얌': 2670,\n",
       " '다치': 12975,\n",
       " '산자': 29430,\n",
       " '##□': 3155,\n",
       " '대법관': 10535,\n",
       " '구요': 5163,\n",
       " '>': 34,\n",
       " '##유산': 9525,\n",
       " '신장': 7827,\n",
       " '관절염': 14202,\n",
       " '영도': 15159,\n",
       " '그쪽': 10576,\n",
       " '포상금': 20648,\n",
       " '강성': 13272,\n",
       " '누굴': 19735,\n",
       " '동메달': 14498,\n",
       " '##찹': 3024,\n",
       " '주저': 8065,\n",
       " '도망쳤': 25157,\n",
       " '수준급': 30378,\n",
       " '엄선': 22497,\n",
       " '##저트': 10008,\n",
       " '곰곰이': 20230,\n",
       " '영유': 18209,\n",
       " '하비': 24380,\n",
       " '빠지': 5893,\n",
       " '에밀': 27369,\n",
       " '##99': 19748,\n",
       " '가져가': 10068,\n",
       " '커다랗': 29341,\n",
       " '진시': 21931,\n",
       " '##oT': 11206,\n",
       " '곡성': 18730,\n",
       " '벗겨지': 30854,\n",
       " '군량': 29176,\n",
       " '퀴즈': 12246,\n",
       " '##리': 2059,\n",
       " 'POS': 28647,\n",
       " '가설': 11535,\n",
       " '성동구': 24482,\n",
       " '##천동': 16183,\n",
       " '##짜고': 28430,\n",
       " '피난처': 27779,\n",
       " '글램': 29418,\n",
       " '🤣': 2004,\n",
       " '참여': 3844,\n",
       " '사들였': 21666,\n",
       " '작동': 7538,\n",
       " '비겁': 22122,\n",
       " '차이나': 19553,\n",
       " '##죽순': 29259,\n",
       " '교': 614,\n",
       " '고령화': 12909,\n",
       " '##틀리': 24314,\n",
       " '호명': 27105,\n",
       " '가슴': 4494,\n",
       " '갖은': 26801,\n",
       " '형사': 5804,\n",
       " '미비': 17282,\n",
       " '잡채': 30113,\n",
       " '##무스': 28877,\n",
       " '불문': 14294,\n",
       " '##보증': 17470,\n",
       " '[unused102]': 31602,\n",
       " '주소': 7862,\n",
       " '정교': 9518,\n",
       " '애쓴': 27356,\n",
       " '블라인드': 23371,\n",
       " '거뒀': 8734,\n",
       " '쓴다는': 22157,\n",
       " '요기': 17103,\n",
       " '뮬': 1104,\n",
       " '피켓': 23077,\n",
       " '북촌': 30440,\n",
       " '##ple': 31439,\n",
       " '줌': 1568,\n",
       " '모씨': 10123,\n",
       " '첫': 1656,\n",
       " '전남': 4997,\n",
       " '스마트폰': 5009,\n",
       " '##크': 2292,\n",
       " '모를': 7595,\n",
       " '영진': 18789,\n",
       " 'Kar': 30317,\n",
       " '배당': 6464,\n",
       " '촬': 1669,\n",
       " '완주': 16039,\n",
       " '다가갔': 16603,\n",
       " '다이어트': 5795,\n",
       " '티스': 21594,\n",
       " '개학': 27379,\n",
       " '[unused74]': 31574,\n",
       " '남긴': 8708,\n",
       " '##돔': 2947,\n",
       " '젓가락': 17547,\n",
       " '49': 5839,\n",
       " '촉촉': 8974,\n",
       " '패했': 18762,\n",
       " '##찍': 3088,\n",
       " '시사점': 24496,\n",
       " '전월': 10865,\n",
       " '##ata': 24335,\n",
       " '##ual': 12757,\n",
       " '##쓴이': 30652,\n",
       " '균형': 5238,\n",
       " '된다면': 6499,\n",
       " '##싫': 3171,\n",
       " '##릇': 3225,\n",
       " 'OO': 27326,\n",
       " '보일지': 28022,\n",
       " '성진': 29075,\n",
       " '포기': 4916,\n",
       " '성동': 12839,\n",
       " '콩': 1733,\n",
       " '난관': 15924,\n",
       " '3800': 25468,\n",
       " '각국': 7120,\n",
       " '백인': 10147,\n",
       " '멋있': 11580,\n",
       " '디딤': 21229,\n",
       " 'ㆍ현': 26143,\n",
       " '연매': 27028,\n",
       " '방위': 9096,\n",
       " '##믿': 2560,\n",
       " '곤지': 30829,\n",
       " '전화기': 14876,\n",
       " '##뒹': 3372,\n",
       " '뜨거운': 6562,\n",
       " '수녀': 14139,\n",
       " '##날리': 18957,\n",
       " '사회학': 13062,\n",
       " '벌금형': 19980,\n",
       " '대검찰청': 20938,\n",
       " '끼여': 23005,\n",
       " '청구': 5300,\n",
       " '스카이': 10500,\n",
       " '노려': 10631,\n",
       " '대략': 10162,\n",
       " '다가왔': 10373,\n",
       " '토해': 17514,\n",
       " '약소': 29817,\n",
       " '그해': 9842,\n",
       " '느끼': 4491,\n",
       " '##의회': 19084,\n",
       " '##ays': 21954,\n",
       " '취득': 6278,\n",
       " '550': 17458,\n",
       " '장성': 8855,\n",
       " '빌릴': 26857,\n",
       " '피로감': 20529,\n",
       " '감사': 4143,\n",
       " '##성이': 11604,\n",
       " 'Organ': 28808,\n",
       " '도시바': 24737,\n",
       " '기발': 18792,\n",
       " '흑': 1959,\n",
       " '강남': 5038,\n",
       " '부림': 17091,\n",
       " '資': 501,\n",
       " '억제': 7546,\n",
       " '1926': 23164,\n",
       " '은서': 21016,\n",
       " '다크': 12393,\n",
       " '볶음밥': 15475,\n",
       " '달군': 31250,\n",
       " '예쁜': 7833,\n",
       " '##TI': 11026,\n",
       " '##반': 2536,\n",
       " '##녁': 3235,\n",
       " '여직': 20365,\n",
       " '초식': 28098,\n",
       " '대통령': 3698,\n",
       " '동생': 5565,\n",
       " '콘서트': 6665,\n",
       " '유방암': 15522,\n",
       " '은수': 19025,\n",
       " '식습관': 19206,\n",
       " '동화책': 24045,\n",
       " '##오피스': 29776,\n",
       " '→': 130,\n",
       " '메기': 28326,\n",
       " '23': 4136,\n",
       " '착하': 15097,\n",
       " '수두': 23475,\n",
       " 'ㆍ의': 28270,\n",
       " '##다': 2062,\n",
       " 'he': 14712,\n",
       " '일수록': 9561,\n",
       " '정상급': 18048,\n",
       " '농민': 6290,\n",
       " '##핑': 2192,\n",
       " 'DNA': 11762,\n",
       " '볼트': 14672,\n",
       " '사령': 6766,\n",
       " '맡기': 8706,\n",
       " '##얼빈': 28915,\n",
       " '##럽': 2319,\n",
       " '증액': 13127,\n",
       " '숲': 1305,\n",
       " '##딩': 2500,\n",
       " '허세': 28362,\n",
       " '##원장': 10293,\n",
       " '숙소': 9206,\n",
       " '##ule': 30480,\n",
       " '순이익': 8660,\n",
       " '쏟아져': 11074,\n",
       " '투성이': 15051,\n",
       " '어처구니없': 28236,\n",
       " '##이브': 7467,\n",
       " '천둥': 19315,\n",
       " '신민': 16720,\n",
       " '나부': 26119,\n",
       " 'KI': 31436,\n",
       " '##78': 24075,\n",
       " '##가분': 27746,\n",
       " '판문점': 13756,\n",
       " '솔라': 24134,\n",
       " '마이클': 10364,\n",
       " '陽': 527,\n",
       " '기술': 3726,\n",
       " '태어났': 9499,\n",
       " '재질': 15495,\n",
       " '안타까움': 17055,\n",
       " '도박': 8902,\n",
       " '아까운': 22596,\n",
       " '함유량': 30995,\n",
       " '여섯': 7070,\n",
       " '만드': 4577,\n",
       " '정태': 17123,\n",
       " '공안': 13164,\n",
       " '관리원': 27271,\n",
       " '이라든가': 14334,\n",
       " '많이': 3732,\n",
       " '선택지': 27687,\n",
       " '소형주': 27743,\n",
       " '사흘': 9229,\n",
       " '김인': 12307,\n",
       " '##종기': 30523,\n",
       " '##셀': 2387,\n",
       " '##버지': 3974,\n",
       " '동요': 12233,\n",
       " '금값': 25628,\n",
       " '##괘': 2655,\n",
       " '문명': 6690,\n",
       " '민법': 14661,\n",
       " '심해졌': 27372,\n",
       " '분자': 12069,\n",
       " '재정난': 27402,\n",
       " '박정희': 8316,\n",
       " '조부모': 30395,\n",
       " '##인물': 14673,\n",
       " '이어질': 7583,\n",
       " '##LPGA': 17265,\n",
       " '문물': 22437,\n",
       " '방학': 7377,\n",
       " '비열': 24415,\n",
       " '오리': 6121,\n",
       " '연': 1431,\n",
       " '모션': 21408,\n",
       " '고운': 13969,\n",
       " '##eng': 23562,\n",
       " '여유': 5707,\n",
       " '자아낸다': 26565,\n",
       " '인내심': 18146,\n",
       " '##차': 2232,\n",
       " '선량': 19177,\n",
       " '장본': 20654,\n",
       " '할리우드': 11979,\n",
       " '중첩': 24033,\n",
       " '광주': 4104,\n",
       " '김동': 7551,\n",
       " '돌아선': 22969,\n",
       " '챙겨야': 22327,\n",
       " '통속': 28090,\n",
       " '추위': 9747,\n",
       " '바스': 15661,\n",
       " '##키': 2089,\n",
       " '자율': 5365,\n",
       " '안위': 25807,\n",
       " '느려': 22425,\n",
       " '이정수': 31348,\n",
       " '곰팡이': 18285,\n",
       " '서문': 12034,\n",
       " '아니야': 16733,\n",
       " '뒤떨': 28788,\n",
       " 'JY': 20973,\n",
       " '눈여겨': 12595,\n",
       " '달성군': 17429,\n",
       " '동방': 11685,\n",
       " '접할': 13266,\n",
       " 'for': 8672,\n",
       " '동행': 9217,\n",
       " '전대': 13224,\n",
       " '##꼴': 2538,\n",
       " '건대': 14206,\n",
       " '프라임': 17443,\n",
       " '##직': 2084,\n",
       " '지극': 9585,\n",
       " '450': 13103,\n",
       " '노심': 27363,\n",
       " '연산': 12492,\n",
       " '노르웨이': 13706,\n",
       " '##무': 2132,\n",
       " '안타까운': 11491,\n",
       " '미분': 10747,\n",
       " '실종자': 15122,\n",
       " 'Res': 15791,\n",
       " '예비': 5251,\n",
       " '기본법': 16594,\n",
       " '불금': 20186,\n",
       " '2000': 4470,\n",
       " '##말리아': 26702,\n",
       " '텁': 1782,\n",
       " '##피탈': 11419,\n",
       " '치닫': 16100,\n",
       " '이해찬': 19013,\n",
       " '햄': 1900,\n",
       " '##닥': 2646,\n",
       " '부메': 29115,\n",
       " '망막': 23318,\n",
       " '숍': 1293,\n",
       " '금호': 7770,\n",
       " '낭만': 9656,\n",
       " '육박': 10760,\n",
       " '제청': 21905,\n",
       " '출점': 26699,\n",
       " '[unused1]': 31501,\n",
       " '나타내': 6269,\n",
       " '##린다고': 18672,\n",
       " '낙엽': 16622,\n",
       " '봐요': 7646,\n",
       " '지상': 5377,\n",
       " '친환경': 5572,\n",
       " 'DTI': 18625,\n",
       " '한남': 24693,\n",
       " '자니': 13202,\n",
       " 'und': 15452,\n",
       " '##ath': 16012,\n",
       " '빵빵': 25159,\n",
       " '약': 1397,\n",
       " '단장': 6738,\n",
       " '총탄': 27142,\n",
       " '액션': 8765,\n",
       " '클러': 10602,\n",
       " '김복': 30238,\n",
       " '미상': 30819,\n",
       " '항공': 4699,\n",
       " '##룽지': 25380,\n",
       " '국유': 14540,\n",
       " '자리매김': 9973,\n",
       " '영월': 17376,\n",
       " '공소시효': 25217,\n",
       " '이대로': 10465,\n",
       " '##먼트': 11257,\n",
       " '어우러져': 15198,\n",
       " '##듬': 2908,\n",
       " '포르투': 11926,\n",
       " '연극제': 23922,\n",
       " '고마웠': 24763,\n",
       " '장정': 17788,\n",
       " '기말': 20304,\n",
       " 'Ⅰ': 126,\n",
       " '오동': 20822,\n",
       " '😍': 2002,\n",
       " '보험금': 9860,\n",
       " '물으': 23172,\n",
       " '교도소': 12381,\n",
       " '##슬러': 9758,\n",
       " '트렌': 6764,\n",
       " '페더': 24672,\n",
       " '외관': 11975,\n",
       " '프라이드': 29211,\n",
       " '심지': 31076,\n",
       " '##출혈': 27547,\n",
       " '릅': 1024,\n",
       " '시학': 30565,\n",
       " '이윤': 8774,\n",
       " '접합': 26138,\n",
       " '카메': 22087,\n",
       " '푸른': 7219,\n",
       " '1961': 16133,\n",
       " '김하늘': 26754,\n",
       " '수의사': 28718,\n",
       " '계약자': 17506,\n",
       " '씩': 1371,\n",
       " '틀림없': 8888,\n",
       " '이듬': 9866,\n",
       " '여': 1428,\n",
       " '水': 411,\n",
       " '어루만지': 26939,\n",
       " '덮': 841,\n",
       " '몸부림': 16101,\n",
       " '[unused490]': 31990,\n",
       " '깨물': 18279,\n",
       " '서스': 28170,\n",
       " '들어왔': 6867,\n",
       " '호주': 6248,\n",
       " '정용': 19898,\n",
       " '##톈': 3209,\n",
       " '총무원': 29596,\n",
       " '마이스터': 21026,\n",
       " '##음료': 20731,\n",
       " '마루': 11027,\n",
       " '일명': 11889,\n",
       " '##럭': 2823,\n",
       " '동서': 8208,\n",
       " '해경': 10752,\n",
       " '커튼': 15098,\n",
       " '유전': 8653,\n",
       " '도랑': 29515,\n",
       " '##뭉': 2693,\n",
       " '##ness': 21570,\n",
       " '##쿠': 2666,\n",
       " '컨설': 6703,\n",
       " '침묵': 7207,\n",
       " '으라': 10444,\n",
       " '##까봐': 21240,\n",
       " '솔로몬': 21293,\n",
       " '진실': 5352,\n",
       " 'petstagram': 31231,\n",
       " '조민': 29688,\n",
       " '하나하나': 9330,\n",
       " '외교': 4770,\n",
       " '임상': 8743,\n",
       " '걸리': 6179,\n",
       " '루마': 22956,\n",
       " '오로라': 28858,\n",
       " '제소': 17374,\n",
       " '이룩': 12215,\n",
       " 'des': 16679,\n",
       " '[unused252]': 31752,\n",
       " '눈여겨보': 28026,\n",
       " '대학가': 21321,\n",
       " '끈적': 22659,\n",
       " '지역': 3634,\n",
       " '청소년': 4857,\n",
       " '출소': 21863,\n",
       " '보합': 23502,\n",
       " '습도': 18070,\n",
       " '변기': 19858,\n",
       " '손상': 7465,\n",
       " '행자부': 26971,\n",
       " '경영인': 20220,\n",
       " '[unused49]': 31549,\n",
       " '퓨전': 18490,\n",
       " '소진': 13547,\n",
       " '헛되': 23568,\n",
       " '스티커': 15005,\n",
       " '나와도': 29164,\n",
       " '울린다': 30999,\n",
       " '위크': 17425,\n",
       " '이루어져': 9914,\n",
       " '에로': 18202,\n",
       " '연임': 14111,\n",
       " '법무부': 8720,\n",
       " '태산': 19494,\n",
       " '모색': 6833,\n",
       " '미즈': 22801,\n",
       " '##옹': 2831,\n",
       " '지구': 4290,\n",
       " '곱창': 14979,\n",
       " '신명': 14953,\n",
       " '피상': 23528,\n",
       " '수련': 9565,\n",
       " '계산': 5394,\n",
       " '저거': 12181,\n",
       " '되살아나': 23976,\n",
       " '어유': 26394,\n",
       " '좋아할': 26020,\n",
       " '협의회': 6097,\n",
       " '푸르지오': 18465,\n",
       " '왕십리': 26529,\n",
       " '##늦': 3167,\n",
       " '왁': 1454,\n",
       " '는다는': 5278,\n",
       " '##16': 21768,\n",
       " '테마주': 24199,\n",
       " '거버넌스': 25052,\n",
       " '미스트': 14573,\n",
       " '##린다': 4127,\n",
       " '실리콘': 10730,\n",
       " '##거지': 12831,\n",
       " '##뉴스': 17171,\n",
       " '넘어지': 16220,\n",
       " '따가운': 28803,\n",
       " '힙합': 13892,\n",
       " '항균': 24596,\n",
       " '눈동자': 12198,\n",
       " '입증': 6850,\n",
       " '끈질': 14580,\n",
       " '##전입': 28727,\n",
       " '[unused290]': 31790,\n",
       " '급물살': 26118,\n",
       " '노인': 4662,\n",
       " '금융업': 23188,\n",
       " '선고': 5779,\n",
       " '라스트': 28225,\n",
       " '차렸': 19852,\n",
       " '##준다': 5675,\n",
       " '##침': 2540,\n",
       " '분단': 9998,\n",
       " '추천서': 26440,\n",
       " '쑤': 1361,\n",
       " '시집': 7936,\n",
       " '햇살': 9778,\n",
       " '도입': 4334,\n",
       " '가급': 12582,\n",
       " '남이': 27141,\n",
       " '부정': 4533,\n",
       " '곁들여': 16645,\n",
       " '삼위일체': 25623,\n",
       " '차창': 25443,\n",
       " '거꾸': 10478,\n",
       " '의석': 13627,\n",
       " '##타': 2256,\n",
       " '베트': 5580,\n",
       " '골칫': 25927,\n",
       " '매우': 4230,\n",
       " '성종': 21186,\n",
       " '##뚫': 3577,\n",
       " '##tis': 16977,\n",
       " '[unused432]': 31932,\n",
       " '[unused307]': 31807,\n",
       " '소비재': 18872,\n",
       " '방대': 13430,\n",
       " '중대장': 30067,\n",
       " '구자철': 21355,\n",
       " '바꿨': 10360,\n",
       " '최성': 17152,\n",
       " '##하르트': 31347,\n",
       " '서둘러야': 25852,\n",
       " '무정부': 29024,\n",
       " '틈새시장': 29028,\n",
       " '2025': 18994,\n",
       " '##촘': 3457,\n",
       " '위험': 4253,\n",
       " '고열': 25620,\n",
       " '귀하': 16045,\n",
       " '엔딩': 17211,\n",
       " '졸': 1555,\n",
       " '등장인물': 16320,\n",
       " '인계': 21518,\n",
       " '1890': 28172,\n",
       " '##래요': 15863,\n",
       " '고엽': 31109,\n",
       " '소위': 6760,\n",
       " '목전': 29245,\n",
       " '가로수': 14764,\n",
       " '##엄마': 31245,\n",
       " '달러화': 14840,\n",
       " '이어진': 9281,\n",
       " '선취': 23191,\n",
       " '던가요': 23069,\n",
       " '마부': 29647,\n",
       " '에덴': 28204,\n",
       " '초저': 20600,\n",
       " '벌일': 13804,\n",
       " '##승부': 15756,\n",
       " '추사': 25966,\n",
       " '지식인': 9803,\n",
       " '자네': 6225,\n",
       " '화폐': 8259,\n",
       " '노루': 24093,\n",
       " '레바': 19419,\n",
       " '휘둥': 28422,\n",
       " '걷어붙': 30708,\n",
       " '##받침': 7894,\n",
       " '관리인': 20981,\n",
       " '한국어': 9187,\n",
       " '건넌': 31382,\n",
       " '이태': 8583,\n",
       " '연호': 25224,\n",
       " '박찬': 10656,\n",
       " '뗄': 917,\n",
       " '췌': 1682,\n",
       " '직업': 5116,\n",
       " '스팅': 30150,\n",
       " '박테리아': 23128,\n",
       " '태풍': 8664,\n",
       " '신학기': 28583,\n",
       " '##을까': 16809,\n",
       " '꾀하': 14110,\n",
       " '베이커리': 19851,\n",
       " '주미': 29752,\n",
       " '무언계': 30027,\n",
       " '##줘': 2810,\n",
       " '인민군': 18507,\n",
       " '연금술': 29877,\n",
       " '치즈': 7241,\n",
       " '現': 430,\n",
       " '펜': 1852,\n",
       " '고스란히': 8838,\n",
       " '토사': 21712,\n",
       " '[unused181]': 31681,\n",
       " '불리': 5039,\n",
       " '노아': 27051,\n",
       " '[unused274]': 31774,\n",
       " '타르': 20891,\n",
       " '난데없이': 31292,\n",
       " '눈시울': 21872,\n",
       " '입시': 6792,\n",
       " '##용준': 27992,\n",
       " '업무상': 19287,\n",
       " 'MRI': 23153,\n",
       " '다투': 10822,\n",
       " '265': 29076,\n",
       " '거라': 12370,\n",
       " '눈알': 30842,\n",
       " '좌측': 19589,\n",
       " '딴': 899,\n",
       " '확신': 6483,\n",
       " '집권당': 26270,\n",
       " '운송인': 30602,\n",
       " '과하': 20171,\n",
       " '하락세': 11652,\n",
       " '돌아오': 5999,\n",
       " '##깬': 3409,\n",
       " '지급': 4589,\n",
       " '1800': 13691,\n",
       " '×': 101,\n",
       " '리턴': 23684,\n",
       " '내릴': 9276,\n",
       " '회개': 22002,\n",
       " '##려면': 19644,\n",
       " '사우나': 21764,\n",
       " '둘러볼': 29048,\n",
       " '##클로': 25221,\n",
       " '사저': 22586,\n",
       " '잣대': 13056,\n",
       " '넘겼': 11391,\n",
       " 'ISO': 25141,\n",
       " '##균': 2510,\n",
       " '##유': 2298,\n",
       " '일어섰': 15808,\n",
       " '치른': 11563,\n",
       " '연료': 7297,\n",
       " '트랜스': 17811,\n",
       " '적십자': 16173,\n",
       " '우유': 7282,\n",
       " '스파이더': 24078,\n",
       " '##인드': 9863,\n",
       " '의무': 5054,\n",
       " '##찾': 2688,\n",
       " '제스처': 21069,\n",
       " '야수': 18732,\n",
       " '구매': 4625,\n",
       " '##테랑': 11916,\n",
       " '통곡': 19750,\n",
       " '스즈키': 26549,\n",
       " '덮친': 28187,\n",
       " '환생': 30364,\n",
       " '토닥': 30584,\n",
       " '비난': 5508,\n",
       " '에다': 6413,\n",
       " '건가': 7582,\n",
       " '통치자': 19680,\n",
       " '문호': 23635,\n",
       " '괜찮': 5110,\n",
       " '##가방': 25607,\n",
       " '뭔': 1098,\n",
       " '字': 314,\n",
       " '플라자': 16597,\n",
       " '자초': 15616,\n",
       " '철저히': 7365,\n",
       " '##소드': 11862,\n",
       " '콥': 1731,\n",
       " '중장': 15093,\n",
       " '가로막': 10750,\n",
       " '냥': 742,\n",
       " '##ision': 20055,\n",
       " '안다는': 25088,\n",
       " '부속': 13024,\n",
       " '단편': 9558,\n",
       " '##회의': 7288,\n",
       " '점쳐': 18890,\n",
       " '##람': 2383,\n",
       " '축구장': 20661,\n",
       " '디지털': 5476,\n",
       " '매표소': 31063,\n",
       " '끌려': 9001,\n",
       " '예견': 13672,\n",
       " '페스트': 31273,\n",
       " '재규어': 24925,\n",
       " '##커녕': 10575,\n",
       " '홍': 1932,\n",
       " '끄덕': 7637,\n",
       " '더샵': 26249,\n",
       " ',': 16,\n",
       " '임기': 6724,\n",
       " '맛집': 5286,\n",
       " '월화': 18549,\n",
       " '간호학': 29891,\n",
       " '반원': 29374,\n",
       " '뒤집어': 17187,\n",
       " '이행': 6162,\n",
       " '대대로': 21723,\n",
       " 'ㅠㅠ': 6516,\n",
       " '젓갈': 23357,\n",
       " '담보': 6484,\n",
       " '요시다': 25564,\n",
       " '뛸': 929,\n",
       " '動': 265,\n",
       " 'ㆍ고': 15595,\n",
       " '조언': 6169,\n",
       " '더불': 4900,\n",
       " '신고자': 26188,\n",
       " '경내': 29739,\n",
       " '국산화': 21014,\n",
       " '##uty': 24170,\n",
       " '##her': 12125,\n",
       " '맞잡': 27850,\n",
       " '[unused200]': 31700,\n",
       " '최규': 28519,\n",
       " '이산': 9072,\n",
       " '[unused417]': 31917,\n",
       " '[unused454]': 31954,\n",
       " '양분': 19058,\n",
       " '##랠': 3529,\n",
       " '##화기': 11211,\n",
       " '반출': 19823,\n",
       " '[unused474]': 31974,\n",
       " '떠올랐': 8234,\n",
       " '화랑': 12819,\n",
       " '##부리': 18442,\n",
       " '레비': 25315,\n",
       " '흠집': 21803,\n",
       " '전문대': 18704,\n",
       " '##운동연합': 20979,\n",
       " '협약': 5598,\n",
       " '생활상': 29223,\n",
       " '##EST': 21511,\n",
       " '일문': 25006,\n",
       " '번창': 25828,\n",
       " '고통': 4855,\n",
       " '##깡': 3127,\n",
       " '쏠렸': 26136,\n",
       " '규율': 14719,\n",
       " '소사이어티': 28530,\n",
       " '선생': 4179,\n",
       " '이동하': 22839,\n",
       " '##벤션': 11752,\n",
       " '히로': 11868,\n",
       " '入': 247,\n",
       " '##스토': 6806,\n",
       " '##섬유': 27377,\n",
       " '##위치': 12765,\n",
       " '임명': 6019,\n",
       " '랠': 955,\n",
       " '성남': 6406,\n",
       " '부총재': 28398,\n",
       " '##터리': 6103,\n",
       " '##아리': 7458,\n",
       " '보석': 9876,\n",
       " '들썩이': 26338,\n",
       " '여운': 15987,\n",
       " '맛나': 15012,\n",
       " '필링': 28407,\n",
       " '나뭇가지': 16033,\n",
       " '문창': 22118,\n",
       " '##yp': 21056,\n",
       " '편집국장': 27555,\n",
       " '수욕장': 31367,\n",
       " '예순': 29704,\n",
       " '평점': 20609,\n",
       " '가장자리': 19193,\n",
       " '악보': 21965,\n",
       " 'the': 5062,\n",
       " '부드러워': 21853,\n",
       " '든다고': 29372,\n",
       " '유정복': 25125,\n",
       " '동선': 16653,\n",
       " '달째': 28690,\n",
       " '회의실': 10917,\n",
       " 'mm': 11245,\n",
       " '사각': 9762,\n",
       " '구인': 13117,\n",
       " '지휘관': 16048,\n",
       " 'A': 37,\n",
       " '잎사귀': 28304,\n",
       " '##탄두': 31177,\n",
       " '유력': 7271,\n",
       " '##엔지니어': 27095,\n",
       " 'MT': 28795,\n",
       " '꺼려': 19983,\n",
       " '##oc': 6624,\n",
       " '희박': 19068,\n",
       " '전학': 20434,\n",
       " '닫힌': 23661,\n",
       " '이충': 31131,\n",
       " '아파': 4093,\n",
       " '강구': 11313,\n",
       " '박인': 12230,\n",
       " '극대': 7548,\n",
       " '헌재': 10316,\n",
       " '영문학': 29872,\n",
       " '동': 856,\n",
       " '처': 1650,\n",
       " '리조트': 7745,\n",
       " '원자재': 11279,\n",
       " '화기애애': 26915,\n",
       " '떠돌이': 31093,\n",
       " '부주석': 27210,\n",
       " '뒤돌아보': 25902,\n",
       " '연대기': 27611,\n",
       " '자장면': 25104,\n",
       " '치른다': 16378,\n",
       " '적용': 4121,\n",
       " '게다가': 5560,\n",
       " '장엄': 21644,\n",
       " '##️': 2652,\n",
       " '##어낸': 16260,\n",
       " '수저': 18664,\n",
       " '인테리어': 8100,\n",
       " 'Dem': 28733,\n",
       " '유아기': 28982,\n",
       " '##꼿': 3371,\n",
       " '비약': 16892,\n",
       " '온누리': 27055,\n",
       " '드리블': 28769,\n",
       " '##나다': 6844,\n",
       " '1980': 6643,\n",
       " '자신': 3638,\n",
       " '매끄럽': 20857,\n",
       " '##스트로': 26169,\n",
       " '후한': 24983,\n",
       " '매끄러운': 30089,\n",
       " '겁니다': 5047,\n",
       " '의인': 23497,\n",
       " 'What': 28868,\n",
       " '균형발전': 12656,\n",
       " '빠진': 6830,\n",
       " '진보당': 25081,\n",
       " '달아오르': 23592,\n",
       " '가창력': 26281,\n",
       " '지게': 27942,\n",
       " '##든지': 7634,\n",
       " '입항': 25539,\n",
       " '시력': 12699,\n",
       " '##본주의': 31401,\n",
       " '망가': 13731,\n",
       " 'PGA': 14246,\n",
       " '교도': 9313,\n",
       " '건강': 3996,\n",
       " '지부': 7854,\n",
       " '##상부': 12298,\n",
       " '신드롬': 23447,\n",
       " '환영': 7130,\n",
       " '추기경': 15847,\n",
       " '스러워했': 30845,\n",
       " '성시': 25694,\n",
       " '작아지': 26831,\n",
       " '폭동': 19487,\n",
       " 'fl': 22232,\n",
       " '기판': 24648,\n",
       " '폭로': 10445,\n",
       " '코디': 13303,\n",
       " '도표': 17706,\n",
       " '풀어': 22457,\n",
       " '비치': 8814,\n",
       " '메트': 31391,\n",
       " '부위원장': 13459,\n",
       " '공간': 4101,\n",
       " '이화': 10687,\n",
       " '잡담': 30046,\n",
       " '대뜸': 23715,\n",
       " '피라미': 17266,\n",
       " '땅볼': 19074,\n",
       " '진정서': 31249,\n",
       " '편안': 5984,\n",
       " '았었': 13003,\n",
       " '맞받': 28056,\n",
       " '##ang': 9617,\n",
       " '부재': 9100,\n",
       " '세법': 16934,\n",
       " '건물': 4515,\n",
       " '넛': 750,\n",
       " '쉬워': 13485,\n",
       " '학창': 15898,\n",
       " '오르내리': 18282,\n",
       " '측정': 6124,\n",
       " '레스': 15962,\n",
       " '##은': 2073,\n",
       " 'IP': 8256,\n",
       " '메타': 16382,\n",
       " '앙금': 26996,\n",
       " '중풍': 29775,\n",
       " '성곽': 22364,\n",
       " '유니버시아드': 26623,\n",
       " '협력': 4203,\n",
       " '##덫': 3546,\n",
       " '의외로': 20068,\n",
       " '외로운': 17474,\n",
       " '참신': 15940,\n",
       " '공장': 4345,\n",
       " '##워크': 5344,\n",
       " '##어진다': 7763,\n",
       " '장진': 27014,\n",
       " '자칫': 8062,\n",
       " '연령': 6524,\n",
       " '##학규': 13601,\n",
       " '##의정': 20032,\n",
       " '##ward': 21181,\n",
       " '##쭤': 3247,\n",
       " '##맛': 2733,\n",
       " '판단': 4150,\n",
       " '##ode': 28401,\n",
       " '땀': 901,\n",
       " '요란': 13080,\n",
       " '한숨': 7470,\n",
       " '협동조합': 10050,\n",
       " '살핀': 21667,\n",
       " '볼일': 19681,\n",
       " '##투스': 12671,\n",
       " '##ural': 19906,\n",
       " '불륜': 22607,\n",
       " '니당': 22710,\n",
       " '주물': 21642,\n",
       " '곤': 596,\n",
       " '스키': 7374,\n",
       " '파급': 12159,\n",
       " '##차림': 13453,\n",
       " '출입문': 18408,\n",
       " '배고파': 20511,\n",
       " '감싼': 29635,\n",
       " '홍문': 22033,\n",
       " '##크라테스': 14537,\n",
       " '열렸': 7099,\n",
       " '분홍': 16143,\n",
       " '교회': 4633,\n",
       " '아득': 17040,\n",
       " '생긴다': 10012,\n",
       " '##드리히': 29521,\n",
       " '옥션': 15583,\n",
       " '라거나': 23516,\n",
       " '[unused10]': 31510,\n",
       " '불똥': 26429,\n",
       " '중령': 22569,\n",
       " '요가': 14657,\n",
       " '2003': 5994,\n",
       " '내심': 14604,\n",
       " '경사': 9892,\n",
       " '진보': 5359,\n",
       " '##ink': 15737,\n",
       " '관계사': 30016,\n",
       " '[unused183]': 31683,\n",
       " '짚': 1594,\n",
       " '형부': 26378,\n",
       " '청했': 21790,\n",
       " '단념': 26969,\n",
       " '특수': 5177,\n",
       " '놀리': 17845,\n",
       " 'pre': 27093,\n",
       " '대청': 17182,\n",
       " '아마추어': 11756,\n",
       " '情': 355,\n",
       " '투옥': 28277,\n",
       " 'Frank': 29774,\n",
       " '예산': 4135,\n",
       " '##페': 2743,\n",
       " ...}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6675e",
   "metadata": {},
   "source": [
    "#### (Special) Token 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d7812922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32001"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_token_num = tokenizer.add_tokens([\"깟뻬뜨랑\", \"케쇽\", \"우뤼갸\", \"쳥쇼\", \"섀료\"])\n",
    "#print(added_token_num)\n",
    "tokenizer.get_vocab()[\"케쇽\"]\n",
    "added_token_num += tokenizer.add_special_tokens({\"additional_special_tokens\":[\"[SHKIM]\", \"[/SHKIM]\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1224b4",
   "metadata": {},
   "source": [
    "만약에 vocab을 새롭게 추가했다면, 반드시 model의 embedding layer 사이즈를 늘려주세요!\n",
    "print(model.get_input_embeddings())\n",
    "model.resize_token_embeddings(tokenizer.vocab_size + added_token_num)\n",
    "print(model.get_input_embeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf804113",
   "metadata": {},
   "source": [
    "#### 여러 문장 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8c0a9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 10661, 2073, 3957, 9652, 2079, 15749, 28674, 18, 3, 636, 2259, 15294, 2069, 4644, 2200, 4597, 2359, 2062, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Tokens (int)      : [2, 10661, 2073, 3957, 9652, 2079, 15749, 28674, 18, 3, 0, 0]\n",
      "Tokens (str)      : ['[CLS]', '이순신', '##은', '조선', '중기', '##의', '무신', '##이다', '.', '[SEP]', '[PAD]', '[PAD]']\n",
      "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "\n",
      "Tokens (int)      : [2, 636, 2259, 15294, 2069, 4644, 2200, 4597, 2359, 2062, 18, 3]\n",
      "Tokens (str)      : ['[CLS]', '그', '##는', '임진왜란', '##을', '승리', '##로', '이끌', '##었', '##다', '.', '[SEP]']\n",
      "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Single segment input\n",
    "single_seg_input = tokenizer(\"이순신은 조선 중기의 무신이다.\")\n",
    "\n",
    "# Multiple segment input\n",
    "multi_seg_input = tokenizer(\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\")\n",
    "\n",
    "print(multi_seg_input)\n",
    "\n",
    "# 배열로 입력하면 출력 결과도 배열로 저장\n",
    "tokens = tokenizer(\n",
    "    [\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \n",
    "    padding=True  # First sentence will have some PADDED tokens to match second sequence length\n",
    ")\n",
    "for i in range(2):\n",
    "    print(\"Tokens (int)      : {}\".format(tokens['input_ids'][i]))\n",
    "    print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in tokens['input_ids'][i]]))\n",
    "    print(\"Tokens (attn_mask): {}\".format(tokens['attention_mask'][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897b5c3",
   "metadata": {},
   "source": [
    "## 데이터 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fef14",
   "metadata": {},
   "source": [
    "### bert tokenizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09665280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "MODEL_NAME = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def myFunction(texts) : \n",
    "    texts_lens = []\n",
    "    word_list = []\n",
    "    word_lens_per_sent = []\n",
    "    \n",
    "    # 문장의 길이를 저장 및 띄어쓰기 단위로 토큰화\n",
    "    for text in texts : \n",
    "        texts_lens.append(len(text))\n",
    "      \n",
    "        # 띄어쓰기 토큰\n",
    "        words = tokenizer.tokenize(text)\n",
    "        word_list.extend(words)\n",
    "        word_lens_per_sent.append(len(words))\n",
    "    \n",
    "    # 문장에 포함된 단어들 카운트\n",
    "    counter = Counter(word_list)\n",
    "    \n",
    "    # 가장 많이 나온 단어 10개\n",
    "    word_list = counter.most_common(n=300)\n",
    "    \n",
    "    # 빈도는 지우고 단어만, 순서대로 저장\n",
    "    word_list = [word[0] for word in word_list]\n",
    "\n",
    "    #TODO. 아래와 같은 두 개의 그래프를 그려 출력해봅시다.\n",
    "    \"\"\"\n",
    "    1. X축에는 코퍼스 내 단어들을 출현 빈도 순으로 정렬하고, Y축은 각 단어들의 출현 빈도를 log-scale로 나타내는 그래프\n",
    "    2. 코퍼스 내의 각 문장들의 단어 개수에 대한 히스토그램\n",
    "    \"\"\"\n",
    "    # 등장 빈도순으로 단어를 정렬하여 시각화\n",
    "    sorted_words = sorted(counter.items(), key=lambda item: (-item[1], item[0]))\n",
    "    sorted_frequency_logscale = [np.log10(el[1]) for el in sorted_words]\n",
    "    indices = np.arange(len(sorted_frequency_logscale))\n",
    "    plt.plot(indices, sorted_frequency_logscale)\n",
    "    plt.ylabel('log10(frequency)', fontsize=16)\n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "\n",
    "    # 문장 단어 개수에 대한 히스토그램 시각화\n",
    "    plt.hist(word_lens_per_sent, bins=20)\n",
    "    plt.xlabel(\"# of words/sent.\")\n",
    "    \n",
    "     \n",
    "    return {\"texts\" : len(texts),\n",
    "            \"num_unique_words\":len(counter),\n",
    "            \"maximum\" : np.max(texts_lens), \"minumum\" : np.min(texts_lens),\n",
    "            \"mean\" : np.mean(texts_lens), \"median\" : np.median(texts_lens),\n",
    "            \"word_maximum\" : np.max(word_lens_per_sent), \"word_minumum\" : np.min(word_lens_per_sent),\n",
    "            \"word_mean\" : np.mean(word_lens_per_sent), \"word_median\" : np.median(word_lens_per_sent),\n",
    "            \"TOP10_word\":word_list}\n",
    "\n",
    "EDA_bert_result = myFunction(out_dataset['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c884d1",
   "metadata": {},
   "source": [
    "(,)제거 필요 : remove_useless_breacket (2-1실습파일)\n",
    "[UNK] 처리 필요 : 토큰 / 스페셜 토큰 추가하기 (3강)\n",
    "\",',‘,“ 처리 : clean_punc : puctuation 정규화 작업\n",
    "1~15... 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef95fcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': 32470,\n",
       " 'num_unique_words': 24478,\n",
       " 'maximum': 455,\n",
       " 'minumum': 14,\n",
       " 'mean': 97.08395441946412,\n",
       " 'median': 87.0,\n",
       " 'word_maximum': 229,\n",
       " 'word_minumum': 7,\n",
       " 'word_mean': 50.95860794579612,\n",
       " 'word_median': 46.0,\n",
       " 'TOP10_word': [',',\n",
       "  '.',\n",
       "  '##의',\n",
       "  '##다',\n",
       "  '##을',\n",
       "  '##에',\n",
       "  '##는',\n",
       "  '##년',\n",
       "  '(',\n",
       "  ')',\n",
       "  '##이',\n",
       "  '##를',\n",
       "  '##은',\n",
       "  '##일',\n",
       "  '##하',\n",
       "  '##로',\n",
       "  '##에서',\n",
       "  '##가',\n",
       "  '##월',\n",
       "  '##고',\n",
       "  '##으로',\n",
       "  '##했',\n",
       "  '##한',\n",
       "  '##과',\n",
       "  '##었',\n",
       "  '##인',\n",
       "  '##와',\n",
       "  '##였',\n",
       "  '있',\n",
       "  '[UNK]',\n",
       "  \"'\",\n",
       "  '\"',\n",
       "  '##대',\n",
       "  '1',\n",
       "  '##게',\n",
       "  '##지',\n",
       "  '##되',\n",
       "  '등',\n",
       "  '##도',\n",
       "  '##당',\n",
       "  '2',\n",
       "  '##이다',\n",
       "  '##자',\n",
       "  '##기',\n",
       "  '이',\n",
       "  '##들',\n",
       "  '##하고',\n",
       "  '3',\n",
       "  '##스',\n",
       "  '##시',\n",
       "  '##장',\n",
       "  '##어',\n",
       "  '그',\n",
       "  '##해',\n",
       "  '##세',\n",
       "  '##며',\n",
       "  '는',\n",
       "  '##던',\n",
       "  '~',\n",
       "  '4',\n",
       "  '-',\n",
       "  '##원',\n",
       "  '##서',\n",
       "  '##군',\n",
       "  '·',\n",
       "  '##으며',\n",
       "  '##부',\n",
       "  '##사',\n",
       "  '은',\n",
       "  '것',\n",
       "  '5',\n",
       "  '##하여',\n",
       "  '##부터',\n",
       "  '##된',\n",
       "  '제',\n",
       "  '되',\n",
       "  '하',\n",
       "  '‘',\n",
       "  '’',\n",
       "  '##회',\n",
       "  '##주',\n",
       "  '##수',\n",
       "  '10',\n",
       "  '##명',\n",
       "  '##국',\n",
       "  '한국',\n",
       "  '##만',\n",
       "  '##학교',\n",
       "  '“',\n",
       "  '6',\n",
       "  '##까',\n",
       "  '”',\n",
       "  '대한민국',\n",
       "  '8',\n",
       "  '전',\n",
       "  '7',\n",
       "  '대표',\n",
       "  '##라',\n",
       "  '고',\n",
       "  '선수',\n",
       "  '##았',\n",
       "  '##리',\n",
       "  '##민',\n",
       "  '함께',\n",
       "  '밝혔',\n",
       "  '##한다',\n",
       "  '11',\n",
       "  '9',\n",
       "  '##관',\n",
       "  '##아',\n",
       "  '대통령',\n",
       "  '##개',\n",
       "  '##전',\n",
       "  '##정',\n",
       "  '이후',\n",
       "  '가',\n",
       "  '12',\n",
       "  '중',\n",
       "  '##상',\n",
       "  '에',\n",
       "  '씨',\n",
       "  '##할',\n",
       "  '##여',\n",
       "  '및',\n",
       "  '후',\n",
       "  '##선',\n",
       "  '##화',\n",
       "  '##보',\n",
       "  '##성',\n",
       "  '##호',\n",
       "  '지난',\n",
       "  '의',\n",
       "  '##다고',\n",
       "  '##트',\n",
       "  '##나',\n",
       "  '수',\n",
       "  '##리그',\n",
       "  '위해',\n",
       "  '경기',\n",
       "  '한',\n",
       "  '##비',\n",
       "  '##학',\n",
       "  '##치',\n",
       "  '##식',\n",
       "  '의원',\n",
       "  '말',\n",
       "  '리그',\n",
       "  '##위',\n",
       "  '미국',\n",
       "  '##왕',\n",
       "  '받',\n",
       "  '을',\n",
       "  '##차',\n",
       "  '##적',\n",
       "  '축구',\n",
       "  '일본',\n",
       "  '##청',\n",
       "  '##타',\n",
       "  '##으나',\n",
       "  '지역',\n",
       "  '##단',\n",
       "  '##적인',\n",
       "  '광주',\n",
       "  '를',\n",
       "  '##동',\n",
       "  '소속',\n",
       "  'FC',\n",
       "  '##들이',\n",
       "  '##드',\n",
       "  '##하기',\n",
       "  '##우',\n",
       "  '##진',\n",
       "  '후보',\n",
       "  '##민주당',\n",
       "  '##제',\n",
       "  '시즌',\n",
       "  '##지만',\n",
       "  '대한',\n",
       "  '##1',\n",
       "  '감독',\n",
       "  '##2',\n",
       "  '##는데',\n",
       "  '##르',\n",
       "  '##미',\n",
       "  '했',\n",
       "  '##현',\n",
       "  '당시',\n",
       "  '서울',\n",
       "  '##오',\n",
       "  '팀',\n",
       "  '국가',\n",
       "  '코',\n",
       "  '로',\n",
       "  '##공',\n",
       "  '기록',\n",
       "  '##적으로',\n",
       "  '않',\n",
       "  '##코',\n",
       "  '##권',\n",
       "  '%',\n",
       "  '통해',\n",
       "  '##번',\n",
       "  '##계',\n",
       "  '##구',\n",
       "  '##후',\n",
       "  '##신',\n",
       "  '##조',\n",
       "  '##소',\n",
       "  '##팀',\n",
       "  '활동',\n",
       "  '##하면',\n",
       "  '##석',\n",
       "  '《',\n",
       "  '##면',\n",
       "  '현재',\n",
       "  '》',\n",
       "  '##영',\n",
       "  '##루',\n",
       "  '##크',\n",
       "  '##레',\n",
       "  '에서',\n",
       "  '오',\n",
       "  '##즈',\n",
       "  '##키',\n",
       "  '정부',\n",
       "  '이라',\n",
       "  '##위원회',\n",
       "  '시작',\n",
       "  '##재',\n",
       "  '때',\n",
       "  '우승',\n",
       "  '##파',\n",
       "  '##실',\n",
       "  '##토',\n",
       "  '회장',\n",
       "  '##중',\n",
       "  '##간',\n",
       "  '##테',\n",
       "  '##니',\n",
       "  '아들',\n",
       "  '##노',\n",
       "  '##면서',\n",
       "  '##형',\n",
       "  '20',\n",
       "  '##프',\n",
       "  '##마',\n",
       "  '##경',\n",
       "  '뒤',\n",
       "  'K',\n",
       "  '국민',\n",
       "  '더불',\n",
       "  '출신',\n",
       "  '##됐',\n",
       "  '두',\n",
       "  '##야',\n",
       "  '##교',\n",
       "  '조선',\n",
       "  '지원',\n",
       "  '##안',\n",
       "  '##준',\n",
       "  '자신',\n",
       "  '##문',\n",
       "  '##3',\n",
       "  '16',\n",
       "  '##억',\n",
       "  '##카',\n",
       "  '##협',\n",
       "  '열린',\n",
       "  '참석',\n",
       "  '와',\n",
       "  '##등',\n",
       "  '##분',\n",
       "  '2019',\n",
       "  '프랑스',\n",
       "  '##티',\n",
       "  '없',\n",
       "  '같',\n",
       "  '주',\n",
       "  '프로',\n",
       "  '##째',\n",
       "  '위한',\n",
       "  '##모',\n",
       "  '##용',\n",
       "  '민주',\n",
       "  '며',\n",
       "  '18',\n",
       "  '참여',\n",
       "  '15',\n",
       "  '유',\n",
       "  '##교육',\n",
       "  '배우',\n",
       "  '##바',\n",
       "  '##대표',\n",
       "  '##터',\n",
       "  '군수',\n",
       "  '운영',\n",
       "  '##위원',\n",
       "  '김',\n",
       "  '시장',\n",
       "  '이적']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_bert_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4ddb3",
   "metadata": {},
   "source": [
    "### bert tokenizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c1a6aec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 32470/32470 [00:07<00:00, 4498.06it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from konlpy.tag import Kkma\n",
    "from konlpy.tag import Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer=Mecab()  \n",
    "#text = \"싸피에서 열공한 우린, 대한민국을 이끌 SW인재\"\n",
    "#print(tokenizer.morphs(text))\n",
    "#['싸', '아', '피', '에서', '열', '공한', '우리', 'ㄴ', ',', '대한민국', '을', '이끌', 'ㄹ', 'SW', '인재']\n",
    "\n",
    "def myFunction(texts) : \n",
    "    texts_lens = []\n",
    "    word_list = []\n",
    "    word_lens_per_sent = []\n",
    "    \n",
    "    # 문장의 길이를 저장 및 형태소 단위로 토큰화\n",
    "    for text in tqdm(texts) : \n",
    "        texts_lens.append(len(text))\n",
    "      \n",
    "        words = tokenizer.morphs(text)\n",
    "        word_list.extend(words)\n",
    "        word_lens_per_sent.append(len(words))\n",
    "    \n",
    "    # 문장에 포함된 단어들 카운트\n",
    "    counter = Counter(word_list)\n",
    "    \n",
    "    # 가장 많이 나온 단어 10개\n",
    "    word_list = counter.most_common(n=300)\n",
    "\n",
    "    # 빈도는 지우고 단어만, 순서대로 저장\n",
    "    word_list = [word[0] for word in word_list]\n",
    "\n",
    "    #TODO. 아래와 같은 두 개의 그래프를 그려 출력해봅시다.\n",
    "    \"\"\"\n",
    "    1. X축에는 코퍼스 내 단어들을 출현 빈도 순으로 정렬하고, Y축은 각 단어들의 출현 빈도를 log-scale로 나타내는 그래프\n",
    "    2. 코퍼스 내의 각 문장들의 단어 개수에 대한 히스토그램\n",
    "    \"\"\"\n",
    "\n",
    "    # 등장 빈도순으로 단어를 정렬하여 시각화\n",
    "    sorted_words = sorted(counter.items(), key=lambda item: (-item[1], item[0]))\n",
    "    sorted_frequency_logscale = [np.log10(el[1]) for el in sorted_words]\n",
    "    indices = np.arange(len(sorted_frequency_logscale))\n",
    "    plt.plot(indices, sorted_frequency_logscale)\n",
    "    plt.ylabel('log10(frequency)', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # 문장 단어 개수에 대한 히스토그램 시각화\n",
    "    plt.hist(word_lens_per_sent, bins=20)\n",
    "    plt.xlabel(\"# of words\")\n",
    "     \n",
    "    return {\"texts\" : len(texts),\n",
    "            \"num_unique_words\":len(counter),\n",
    "            \"maximum\" : np.max(texts_lens), \"minumum\" : np.min(texts_lens),\n",
    "            \"mean\" : np.mean(texts_lens), \"median\" : np.median(texts_lens),\n",
    "            \"word_maximum\" : np.max(word_lens_per_sent), \"word_minumum\" : np.min(word_lens_per_sent),\n",
    "            \"word_mean\" : np.mean(word_lens_per_sent), \"word_median\" : np.median(word_lens_per_sent),\n",
    "            \"TOP10_word\":word_list[:300]}\n",
    "\n",
    "EDA_Mecab_result = myFunction(out_dataset['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "867b893c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': 32470,\n",
       " 'num_unique_words': 61365,\n",
       " 'maximum': 455,\n",
       " 'minumum': 14,\n",
       " 'mean': 97.08395441946412,\n",
       " 'median': 87.0,\n",
       " 'word_maximum': 204,\n",
       " 'word_minumum': 7,\n",
       " 'word_mean': 45.28376963350785,\n",
       " 'word_median': 40.0,\n",
       " 'TOP10_word': [',',\n",
       "  '의',\n",
       "  '.',\n",
       "  '다',\n",
       "  '을',\n",
       "  '이',\n",
       "  '는',\n",
       "  '에',\n",
       "  '하',\n",
       "  '년',\n",
       "  '(',\n",
       "  '를',\n",
       "  ')',\n",
       "  '은',\n",
       "  '고',\n",
       "  '일',\n",
       "  '에서',\n",
       "  '가',\n",
       "  '로',\n",
       "  '으로',\n",
       "  '월',\n",
       "  '한',\n",
       "  '했',\n",
       "  '과',\n",
       "  '와',\n",
       "  '었',\n",
       "  '인',\n",
       "  '되',\n",
       "  '있',\n",
       "  '였',\n",
       "  \"'\",\n",
       "  '1',\n",
       "  '들',\n",
       "  '2',\n",
       "  '\"',\n",
       "  '등',\n",
       "  '도',\n",
       "  '3',\n",
       "  '어',\n",
       "  '여',\n",
       "  '며',\n",
       "  '그',\n",
       "  '적',\n",
       "  '해',\n",
       "  '기',\n",
       "  '던',\n",
       "  '4',\n",
       "  '세',\n",
       "  '-',\n",
       "  '·',\n",
       "  '자',\n",
       "  '게',\n",
       "  '당',\n",
       "  '대표',\n",
       "  '것',\n",
       "  '5',\n",
       "  '리그',\n",
       "  '전',\n",
       "  '제',\n",
       "  '된',\n",
       "  '대',\n",
       "  '에게',\n",
       "  '‘',\n",
       "  '씨',\n",
       "  '10',\n",
       "  '6',\n",
       "  '지',\n",
       "  '선수',\n",
       "  '명',\n",
       "  '까지',\n",
       "  '받',\n",
       "  '7',\n",
       "  '8',\n",
       "  '“',\n",
       "  '부터',\n",
       "  '”',\n",
       "  '’',\n",
       "  '팀',\n",
       "  '대한민국',\n",
       "  '한국',\n",
       "  '만',\n",
       "  '경기',\n",
       "  '면서',\n",
       "  '았',\n",
       "  '함께',\n",
       "  '9',\n",
       "  '11',\n",
       "  '중',\n",
       "  '밝혔',\n",
       "  '할',\n",
       "  '~',\n",
       "  '대통령',\n",
       "  '12',\n",
       "  '한다',\n",
       "  '이후',\n",
       "  '수',\n",
       "  '및',\n",
       "  '의원',\n",
       "  '후',\n",
       "  '다고',\n",
       "  '지역',\n",
       "  '후보',\n",
       "  '대학교',\n",
       "  '지난',\n",
       "  '아',\n",
       "  '~)',\n",
       "  '위해',\n",
       "  '축구',\n",
       "  '말',\n",
       "  '시즌',\n",
       "  '미국',\n",
       "  '으며',\n",
       "  '라고',\n",
       "  '민주당',\n",
       "  '원',\n",
       "  '서울',\n",
       "  '번',\n",
       "  '소속',\n",
       "  '일본',\n",
       "  '개',\n",
       "  '라는',\n",
       "  'FC',\n",
       "  '지만',\n",
       "  '주',\n",
       "  '19',\n",
       "  '시장',\n",
       "  '감독',\n",
       "  '대한',\n",
       "  '시',\n",
       "  '그룹',\n",
       "  '사업',\n",
       "  '활동',\n",
       "  '지원',\n",
       "  '정부',\n",
       "  '당시',\n",
       "  '국가',\n",
       "  '회장',\n",
       "  '위원회',\n",
       "  '기록',\n",
       "  '대학',\n",
       "  '차',\n",
       "  '광주',\n",
       "  '않',\n",
       "  '두',\n",
       "  '부',\n",
       "  '통해',\n",
       "  '위',\n",
       "  '는데',\n",
       "  '됐',\n",
       "  '화',\n",
       "  '성',\n",
       "  '때',\n",
       "  '나',\n",
       "  '《',\n",
       "  '우승',\n",
       "  '현재',\n",
       "  '면',\n",
       "  '조선',\n",
       "  '20',\n",
       "  '장관',\n",
       "  '시작',\n",
       "  '군',\n",
       "  '아들',\n",
       "  '권',\n",
       "  '대회',\n",
       "  '더불',\n",
       "  '군수',\n",
       "  '방송',\n",
       "  '출신',\n",
       "  '뒤',\n",
       "  '간',\n",
       "  '16',\n",
       "  '학교',\n",
       "  '내',\n",
       "  '회',\n",
       "  '사',\n",
       "  '국민',\n",
       "  '같',\n",
       "  '사회',\n",
       "  '자신',\n",
       "  '15',\n",
       "  '》',\n",
       "  '위원장',\n",
       "  '열린',\n",
       "  '교육',\n",
       "  '18',\n",
       "  '참석',\n",
       "  '운영',\n",
       "  '데',\n",
       "  '없',\n",
       "  '참여',\n",
       "  '세계',\n",
       "  '위한',\n",
       "  '2019',\n",
       "  '13',\n",
       "  '오',\n",
       "  '째',\n",
       "  '배우',\n",
       "  '억',\n",
       "  '안',\n",
       "  '총장',\n",
       "  '겠',\n",
       "  '신',\n",
       "  '라',\n",
       "  '국제',\n",
       "  '분',\n",
       "  '17',\n",
       "  '프랑스',\n",
       "  '장',\n",
       "  '된다',\n",
       "  '30',\n",
       "  '25',\n",
       "  '다는',\n",
       "  ':',\n",
       "  '트',\n",
       "  '사장',\n",
       "  '민주',\n",
       "  '프로',\n",
       "  '맡',\n",
       "  '기업',\n",
       "  '첫',\n",
       "  '21',\n",
       "  '코로나',\n",
       "  '왕',\n",
       "  '개최',\n",
       "  '기관',\n",
       "  '자유',\n",
       "  '선거',\n",
       "  '정치',\n",
       "  '지방',\n",
       "  '였으며',\n",
       "  '이적',\n",
       "  '센터',\n",
       "  '이날',\n",
       "  '14',\n",
       "  '이름',\n",
       "  '%',\n",
       "  '진행',\n",
       "  '설립',\n",
       "  '통합',\n",
       "  '국회의원',\n",
       "  '했으며',\n",
       "  '골',\n",
       "  '독일',\n",
       "  '관련',\n",
       "  '제국',\n",
       "  '24',\n",
       "  '중앙',\n",
       "  '2020',\n",
       "  '비롯',\n",
       "  '국회',\n",
       "  '더',\n",
       "  '23',\n",
       "  '26',\n",
       "  '테',\n",
       "  '따라',\n",
       "  '공동',\n",
       "  '추진',\n",
       "  '형',\n",
       "  '영국',\n",
       "  '사이',\n",
       "  '문화',\n",
       "  'K',\n",
       "  '전남',\n",
       "  '가수',\n",
       "  '데뷔',\n",
       "  '상',\n",
       "  '부산',\n",
       "  '위원',\n",
       "  '경제',\n",
       "  '28',\n",
       "  '22',\n",
       "  '대해',\n",
       "  '발표',\n",
       "  '활약',\n",
       "  '가운데',\n",
       "  '라며',\n",
       "  '사건',\n",
       "  '중국',\n",
       "  '산업',\n",
       "  '27',\n",
       "  '로서',\n",
       "  '보',\n",
       "  '다시',\n",
       "  '다가',\n",
       "  '본부',\n",
       "  '기술',\n",
       "  '서',\n",
       "  '미래',\n",
       "  '한편',\n",
       "  '새',\n",
       "  '최고',\n",
       "  '계약',\n",
       "  '동안',\n",
       "  '2011',\n",
       "  '교수',\n",
       "  '정책',\n",
       "  '주장',\n",
       "  '그리고',\n",
       "  '2010']}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_Mecab_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9fef11d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': 32470,\n",
       " 'num_unique_words': 24478,\n",
       " 'maximum': 455,\n",
       " 'minumum': 14,\n",
       " 'mean': 97.08395441946412,\n",
       " 'median': 87.0,\n",
       " 'word_maximum': 229,\n",
       " 'word_minumum': 7,\n",
       " 'word_mean': 50.95860794579612,\n",
       " 'word_median': 46.0,\n",
       " 'TOP10_word': [',',\n",
       "  '.',\n",
       "  '##의',\n",
       "  '##다',\n",
       "  '##을',\n",
       "  '##에',\n",
       "  '##는',\n",
       "  '##년',\n",
       "  '(',\n",
       "  ')',\n",
       "  '##이',\n",
       "  '##를',\n",
       "  '##은',\n",
       "  '##일',\n",
       "  '##하',\n",
       "  '##로',\n",
       "  '##에서',\n",
       "  '##가',\n",
       "  '##월',\n",
       "  '##고',\n",
       "  '##으로',\n",
       "  '##했',\n",
       "  '##한',\n",
       "  '##과',\n",
       "  '##었',\n",
       "  '##인',\n",
       "  '##와',\n",
       "  '##였',\n",
       "  '있',\n",
       "  '[UNK]',\n",
       "  \"'\",\n",
       "  '\"',\n",
       "  '##대',\n",
       "  '1',\n",
       "  '##게',\n",
       "  '##지',\n",
       "  '##되',\n",
       "  '등',\n",
       "  '##도',\n",
       "  '##당',\n",
       "  '2',\n",
       "  '##이다',\n",
       "  '##자',\n",
       "  '##기',\n",
       "  '이',\n",
       "  '##들',\n",
       "  '##하고',\n",
       "  '3',\n",
       "  '##스',\n",
       "  '##시',\n",
       "  '##장',\n",
       "  '##어',\n",
       "  '그',\n",
       "  '##해',\n",
       "  '##세',\n",
       "  '##며',\n",
       "  '는',\n",
       "  '##던',\n",
       "  '~',\n",
       "  '4',\n",
       "  '-',\n",
       "  '##원',\n",
       "  '##서',\n",
       "  '##군',\n",
       "  '·',\n",
       "  '##으며',\n",
       "  '##부',\n",
       "  '##사',\n",
       "  '은',\n",
       "  '것',\n",
       "  '5',\n",
       "  '##하여',\n",
       "  '##부터',\n",
       "  '##된',\n",
       "  '제',\n",
       "  '되',\n",
       "  '하',\n",
       "  '‘',\n",
       "  '’',\n",
       "  '##회',\n",
       "  '##주',\n",
       "  '##수',\n",
       "  '10',\n",
       "  '##명',\n",
       "  '##국',\n",
       "  '한국',\n",
       "  '##만',\n",
       "  '##학교',\n",
       "  '“',\n",
       "  '6',\n",
       "  '##까',\n",
       "  '”',\n",
       "  '대한민국',\n",
       "  '8',\n",
       "  '전',\n",
       "  '7',\n",
       "  '대표',\n",
       "  '##라',\n",
       "  '고',\n",
       "  '선수',\n",
       "  '##았',\n",
       "  '##리',\n",
       "  '##민',\n",
       "  '함께',\n",
       "  '밝혔',\n",
       "  '##한다',\n",
       "  '11',\n",
       "  '9',\n",
       "  '##관',\n",
       "  '##아',\n",
       "  '대통령',\n",
       "  '##개',\n",
       "  '##전',\n",
       "  '##정',\n",
       "  '이후',\n",
       "  '가',\n",
       "  '12',\n",
       "  '중',\n",
       "  '##상',\n",
       "  '에',\n",
       "  '씨',\n",
       "  '##할',\n",
       "  '##여',\n",
       "  '및',\n",
       "  '후',\n",
       "  '##선',\n",
       "  '##화',\n",
       "  '##보',\n",
       "  '##성',\n",
       "  '##호',\n",
       "  '지난',\n",
       "  '의',\n",
       "  '##다고',\n",
       "  '##트',\n",
       "  '##나',\n",
       "  '수',\n",
       "  '##리그',\n",
       "  '위해',\n",
       "  '경기',\n",
       "  '한',\n",
       "  '##비',\n",
       "  '##학',\n",
       "  '##치',\n",
       "  '##식',\n",
       "  '의원',\n",
       "  '말',\n",
       "  '리그',\n",
       "  '##위',\n",
       "  '미국',\n",
       "  '##왕',\n",
       "  '받',\n",
       "  '을',\n",
       "  '##차',\n",
       "  '##적',\n",
       "  '축구',\n",
       "  '일본',\n",
       "  '##청',\n",
       "  '##타',\n",
       "  '##으나',\n",
       "  '지역',\n",
       "  '##단',\n",
       "  '##적인',\n",
       "  '광주',\n",
       "  '를',\n",
       "  '##동',\n",
       "  '소속',\n",
       "  'FC',\n",
       "  '##들이',\n",
       "  '##드',\n",
       "  '##하기',\n",
       "  '##우',\n",
       "  '##진',\n",
       "  '후보',\n",
       "  '##민주당',\n",
       "  '##제',\n",
       "  '시즌',\n",
       "  '##지만',\n",
       "  '대한',\n",
       "  '##1',\n",
       "  '감독',\n",
       "  '##2',\n",
       "  '##는데',\n",
       "  '##르',\n",
       "  '##미',\n",
       "  '했',\n",
       "  '##현',\n",
       "  '당시',\n",
       "  '서울',\n",
       "  '##오',\n",
       "  '팀',\n",
       "  '국가',\n",
       "  '코',\n",
       "  '로',\n",
       "  '##공',\n",
       "  '기록',\n",
       "  '##적으로',\n",
       "  '않',\n",
       "  '##코',\n",
       "  '##권',\n",
       "  '%',\n",
       "  '통해',\n",
       "  '##번',\n",
       "  '##계',\n",
       "  '##구',\n",
       "  '##후',\n",
       "  '##신',\n",
       "  '##조',\n",
       "  '##소',\n",
       "  '##팀',\n",
       "  '활동',\n",
       "  '##하면',\n",
       "  '##석',\n",
       "  '《',\n",
       "  '##면',\n",
       "  '현재',\n",
       "  '》',\n",
       "  '##영',\n",
       "  '##루',\n",
       "  '##크',\n",
       "  '##레',\n",
       "  '에서',\n",
       "  '오',\n",
       "  '##즈',\n",
       "  '##키',\n",
       "  '정부',\n",
       "  '이라',\n",
       "  '##위원회',\n",
       "  '시작',\n",
       "  '##재',\n",
       "  '때',\n",
       "  '우승',\n",
       "  '##파',\n",
       "  '##실',\n",
       "  '##토',\n",
       "  '회장',\n",
       "  '##중',\n",
       "  '##간',\n",
       "  '##테',\n",
       "  '##니',\n",
       "  '아들',\n",
       "  '##노',\n",
       "  '##면서',\n",
       "  '##형',\n",
       "  '20',\n",
       "  '##프',\n",
       "  '##마',\n",
       "  '##경',\n",
       "  '뒤',\n",
       "  'K',\n",
       "  '국민',\n",
       "  '더불',\n",
       "  '출신',\n",
       "  '##됐',\n",
       "  '두',\n",
       "  '##야',\n",
       "  '##교',\n",
       "  '조선',\n",
       "  '지원',\n",
       "  '##안',\n",
       "  '##준',\n",
       "  '자신',\n",
       "  '##문',\n",
       "  '##3',\n",
       "  '16',\n",
       "  '##억',\n",
       "  '##카',\n",
       "  '##협',\n",
       "  '열린',\n",
       "  '참석',\n",
       "  '와',\n",
       "  '##등',\n",
       "  '##분',\n",
       "  '2019',\n",
       "  '프랑스',\n",
       "  '##티',\n",
       "  '없',\n",
       "  '같',\n",
       "  '주',\n",
       "  '프로',\n",
       "  '##째',\n",
       "  '위한',\n",
       "  '##모',\n",
       "  '##용',\n",
       "  '민주',\n",
       "  '며',\n",
       "  '18',\n",
       "  '참여',\n",
       "  '15',\n",
       "  '유',\n",
       "  '##교육',\n",
       "  '배우',\n",
       "  '##바',\n",
       "  '##대표',\n",
       "  '##터',\n",
       "  '군수',\n",
       "  '운영',\n",
       "  '##위원',\n",
       "  '김',\n",
       "  '시장',\n",
       "  '이적']}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDA_bert_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fc5df569",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2878/3423510598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#['싸', '아', '피', '에서', '열', '공한', '우리', 'ㄴ', ',', '대한민국', '을', '이끌', 'ㄹ', 'SW', '인재']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'惠寧君 李𥘺'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# out_dataset['sentence'][3926] # 여기서 오류남 한자때문으로 추정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#혜령군 이정 또는 이지(惠寧君 李𥘺 또는 李祉, 1407년 ~ 1440년)은 조선의 왕족으로 태종의 넷째 서자이다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     68\u001b[0m                             \u001b[0mmorphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                             \u001b[0mmorphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer=Kkma()  \n",
    "#text = \"싸피에서 열공한 우린, 대한민국을 이끌 SW인재\"\n",
    "#print(tokenizer.morphs(text))\n",
    "#['싸', '아', '피', '에서', '열', '공한', '우리', 'ㄴ', ',', '대한민국', '을', '이끌', 'ㄹ', 'SW', '인재']\n",
    "\n",
    "tokenizer.morphs('惠寧君 李𥘺'.encode(\"utf-16\").decode(\"utf-16\"))\n",
    "# out_dataset['sentence'][3926] # 여기서 오류남 한자때문으로 추정\n",
    "#혜령군 이정 또는 이지(惠寧君 李𥘺 또는 李祉, 1407년 ~ 1440년)은 조선의 왕족으로 태종의 넷째 서자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "945c8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████████▍                                                                                   | 3926/32470 [02:49<20:31, 23.18it/s]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2878/2628958834.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \"TOP10_word\":word_list[:300]}\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mEDA_Kkma_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2878/2628958834.py\u001b[0m in \u001b[0;36mmyFunction\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtexts_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mword_lens_per_sent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mmorphs\u001b[0;34m(self, phrase)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;34m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/konlpy/tag/_kkma.py\u001b[0m in \u001b[0;36mpos\u001b[0;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[1;32m     68\u001b[0m                             \u001b[0mmorphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                             \u001b[0mmorphemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmorpheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xed in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer=Kkma()  \n",
    "#text = \"싸피에서 열공한 우린, 대한민국을 이끌 SW인재\"\n",
    "#print(tokenizer.morphs(text))\n",
    "#['싸', '아', '피', '에서', '열', '공한', '우리', 'ㄴ', ',', '대한민국', '을', '이끌', 'ㄹ', 'SW', '인재']\n",
    "\n",
    "def myFunction(texts) : \n",
    "    texts_lens = []\n",
    "    word_list = []\n",
    "    word_lens_per_sent = []\n",
    "    \n",
    "    # 문장의 길이를 저장 및 형태소 단위로 토큰화\n",
    "    for text in tqdm(texts) : \n",
    "        texts_lens.append(len(text))\n",
    "      \n",
    "        words = tokenizer.morphs(text)\n",
    "        word_list.extend(words)\n",
    "        word_lens_per_sent.append(len(words))\n",
    "    \n",
    "    # 문장에 포함된 단어들 카운트\n",
    "    counter = Counter(word_list)\n",
    "    \n",
    "    # 가장 많이 나온 단어 10개\n",
    "    word_list = counter.most_common(n=300)\n",
    "\n",
    "    # 빈도는 지우고 단어만, 순서대로 저장\n",
    "    word_list = [word[0] for word in word_list]\n",
    "\n",
    "    #TODO. 아래와 같은 두 개의 그래프를 그려 출력해봅시다.\n",
    "    \"\"\"\n",
    "    1. X축에는 코퍼스 내 단어들을 출현 빈도 순으로 정렬하고, Y축은 각 단어들의 출현 빈도를 log-scale로 나타내는 그래프\n",
    "    2. 코퍼스 내의 각 문장들의 단어 개수에 대한 히스토그램\n",
    "    \"\"\"\n",
    "\n",
    "    # 등장 빈도순으로 단어를 정렬하여 시각화\n",
    "    sorted_words = sorted(counter.items(), key=lambda item: (-item[1], item[0]))\n",
    "    sorted_frequency_logscale = [np.log10(el[1]) for el in sorted_words]\n",
    "    indices = np.arange(len(sorted_frequency_logscale))\n",
    "    plt.plot(indices, sorted_frequency_logscale)\n",
    "    plt.ylabel('log10(frequency)', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # 문장 단어 개수에 대한 히스토그램 시각화\n",
    "    plt.hist(word_lens_per_sent, bins=20)\n",
    "    plt.xlabel(\"# of words\")\n",
    "     \n",
    "    return {\"texts\" : len(texts),\n",
    "            \"num_unique_words\":len(counter),\n",
    "            \"maximum\" : np.max(texts_lens), \"minumum\" : np.min(texts_lens),\n",
    "            \"mean\" : np.mean(texts_lens), \"median\" : np.median(texts_lens),\n",
    "            \"word_maximum\" : np.max(word_lens_per_sent), \"word_minumum\" : np.min(word_lens_per_sent),\n",
    "            \"word_mean\" : np.mean(word_lens_per_sent), \"word_median\" : np.median(word_lens_per_sent),\n",
    "            \"TOP10_word\":word_list[:300]}\n",
    "\n",
    "EDA_Kkma_result = myFunction(out_dataset['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a89df",
   "metadata": {},
   "source": [
    "## 모델 출력 결과확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tokens_pt = tokenizer(\"이순신은 조선 중기의 무신이다.\", return_tensors=\"pt\")\n",
    "for key, value in tokens_pt.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))\n",
    "\n",
    "outputs = model(**tokens_pt)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "pooler_output = outputs.pooler_output\n",
    "\n",
    "print(\"\\nToken wise output: {}, Pooled output: {}\".format(last_hidden_state.shape, pooler_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf56a7",
   "metadata": {},
   "source": [
    "### 모델 출력 결과확인하기 - datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33102b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_config =  AutoConfig.from_pretrained(MODEL_NAME)\n",
    "model_config.num_labels = 30\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, config=model_config)\n",
    "\n",
    "model.parameters\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fca46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(    # [MASK] 를 씌우는 것은 저희가 구현하지 않아도 됩니다! :-)\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaeba8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,   168, 30985, 14451,  7088,  4586,   169,   793,  8373, 14113,\n",
      "          2234,  2052,  1363,  2088, 29830,  2116, 14879,  2440,  6711,   170,\n",
      "         21406, 26713,  2076, 25145,  5749,   171,  1421,   818,  2073,  4388,\n",
      "          2062,    18,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(out_dataset['sentence'][0], return_tensors=\"pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e5c13ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['〈', 'S', 'o', 'm', 'e', 't', 'h', 'i', 'n', 'g', '〉', '는', ' '] ['조', '지', ' ', '해', '리', '슨', '이', ' ', '쓰', '고', ' ', '비', '틀', '즈', '가', ' ', '1', '9', '6', '9', '년', ' ', '앨', '범', ' ', '《', 'A', 'b', 'b', 'e', 'y', ' ', 'R', 'o', 'a', 'd', '》', '에', ' ', '담', '은', ' ', '노', '래', '다', '.']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9724/1249823241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# 그럼 다음은.. 이 데이터에 [MASK] 를 씌워야겠죠?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 example = {\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                     \u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;34m\"next_sentence_label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_random_next\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2151\u001b[0m                 ``convert_tokens_to_ids`` method).\n\u001b[1;32m   2152\u001b[0m         \"\"\"\n\u001b[0;32m-> 2153\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2154\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2470\u001b[0m         )\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2473\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    479\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    403\u001b[0m         )\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "examples = []\n",
    "# 본격적으로 학습을 위한 데이터로 변형시켜볼까요?\n",
    "for doc_index, document in enumerate(out_dataset['sentence']):\n",
    "    document = tokenizer.tokenize(document)\n",
    "    document = tokenizer.convert_tokens_to_ids(document)\n",
    "    max_num_tokens = 128 - tokenizer.num_special_tokens_to_add(pair=True)\n",
    "    target_seq_length = max_num_tokens\n",
    "    if random.random() < 0.1:\n",
    "        target_seq_length = random.randint(2, max_num_tokens)\n",
    "\n",
    "    current_chunk = []  # a buffer stored current working segments\n",
    "    current_length = 0\n",
    "    i = 0\n",
    "\n",
    "    # 데이터 구축의 단위는 document 입니다\n",
    "    # 이 때, 무조건 문장_1[SEP]문장_2 이렇게 만들어지는 것이 아니라,\n",
    "    # 126 token을 꽉 채울 수 있게 문장_1+문장_2[SEP]문장_3+문장_4 형태로 만들어질 수 있습니다.\n",
    "    while i < len(document):\n",
    "        segment = document[i]\n",
    "        current_chunk.append(segment)\n",
    "        current_length += len(segment)\n",
    "        if i == len(document) - 1 or current_length >= target_seq_length:\n",
    "            if current_chunk:\n",
    "                # `a_end` is how many segments from `current_chunk` go into the `A`\n",
    "                # (first) sentence.\n",
    "                a_end = 1\n",
    "                # 여기서 문장_1+문장_2 가 이루어졌을 때, 길이를 random하게 짤라버립니다 :-)\n",
    "                if len(current_chunk) >= 2:\n",
    "                    a_end = random.randint(1, len(current_chunk) - 1)\n",
    "                tokens_a = []\n",
    "                for j in range(a_end):\n",
    "                    tokens_a.extend(current_chunk[j])\n",
    "                # 이제 [SEP] 뒷 부분인 segmentB를 살펴볼까요?\n",
    "                tokens_b = []\n",
    "                # 50%의 확률로 랜덤하게 다른 문장을 선택하거나, 다음 문장을 학습데이터로 만듭니다.\n",
    "                if len(current_chunk) == 1 or random.random() < 0.5:\n",
    "                    is_random_next = True\n",
    "                    target_b_length = target_seq_length - len(tokens_a)\n",
    "\n",
    "                    # This should rarely go for more than one iteration for large\n",
    "                    # corpora. However, just to be careful, we try to make sure that\n",
    "                    # the random document is not the same as the document\n",
    "                    # we're processing.\n",
    "                    for _ in range(10):\n",
    "                        random_document_index = random.randint(0, len(out_dataset['sentence']) - 1)\n",
    "                        if random_document_index != doc_index:\n",
    "                            break\n",
    "                    # 여기서 랜덤하게 선택합니다 :-)\n",
    "                    random_document = out_dataset['sentence'][random_document_index]\n",
    "                    random_start = random.randint(0, len(random_document) - 1)\n",
    "                    for j in range(random_start, len(random_document)):\n",
    "                        tokens_b.extend(random_document[j])\n",
    "                        if len(tokens_b) >= target_b_length:\n",
    "                            break\n",
    "                    # We didn't actually use these segments so we \"put them back\" so\n",
    "                    # they don't go to waste.\n",
    "                    num_unused_segments = len(current_chunk) - a_end\n",
    "                    i -= num_unused_segments\n",
    "                # Actual next\n",
    "                else:\n",
    "                    is_random_next = False\n",
    "                    for j in range(a_end, len(current_chunk)):\n",
    "                        tokens_b.extend(current_chunk[j])\n",
    "\n",
    "                # 이제 126 token을 넘는다면 truncation을 해야합니다.\n",
    "                # 이 때, 126 token 이내로 들어온다면 행위를 멈추고,\n",
    "                # 만약 126 token을 넘는다면, segmentA와 segmentB에서 랜덤하게 하나씩 제거합니다.\n",
    "                def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens):\n",
    "                    \"\"\"Truncates a pair of sequences to a maximum sequence length.\"\"\"\n",
    "                    while True:\n",
    "                        total_length = len(tokens_a) + len(tokens_b)\n",
    "                        if total_length <= max_num_tokens:\n",
    "                            break\n",
    "                        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n",
    "                        assert len(trunc_tokens) >= 1\n",
    "                        # We want to sometimes truncate from the front and sometimes from the\n",
    "                        # back to add more randomness and avoid biases.\n",
    "                        if random.random() < 0.5:\n",
    "                            del trunc_tokens[0]\n",
    "                        else:\n",
    "                            trunc_tokens.pop()\n",
    "\n",
    "                truncate_seq_pair(tokens_a, tokens_b, max_num_tokens)\n",
    "\n",
    "                assert len(tokens_a) >= 1\n",
    "                assert len(tokens_b) >= 1\n",
    "\n",
    "                # add special tokens\n",
    "                print(tokens_a, tokens_b)\n",
    "                input_ids = tokenizer.build_inputs_with_special_tokens(tokens_a, tokens_b)\n",
    "                # add token type ids, 0 for sentence a, 1 for sentence b\n",
    "                token_type_ids = tokenizer.create_token_type_ids_from_sequences(tokens_a, tokens_b)\n",
    "\n",
    "                # 드디어 아래 항목에 대한 데이터셋이 만들어졌습니다! :-)\n",
    "                # 즉, segmentA[SEP]segmentB, [0, 0, .., 0, 1, 1, ..., 1], NSP 데이터가 만들어진 것입니다 :-)\n",
    "                # 그럼 다음은.. 이 데이터에 [MASK] 를 씌워야겠죠?\n",
    "                example = {\n",
    "                    \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "                    \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                    \"next_sentence_label\": torch.tensor(1 if is_random_next else 0, dtype=torch.long),\n",
    "                }\n",
    "\n",
    "                examples.append(example)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6632a55",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Encoding' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9724/2202270685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(data_collator(tokenizer(out_dataset['sentence'][0], return_tensors=\"pt\", padding=True,\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       max_length=256)))\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             batch = {\n\u001b[0;32m--> 674\u001b[0;31m                 \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_torch_collate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m             }\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m_torch_collate_batch\u001b[0;34m(examples, tokenizer, pad_to_multiple_of)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mlength_of_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# Check if padding is necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tokenizers.Encoding' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "print(data_collator(tokenizer(out_dataset['sentence'][0], return_tensors=\"pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='model_output',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_gpu_train_batch_size=32,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=100\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
