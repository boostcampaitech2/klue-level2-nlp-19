{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4RUMz0g2daz"
   },
   "source": [
    "# 1. data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taWouE4B2ctn",
    "outputId": "5a84005e-a851-4afa-d1e3-b8704735b2b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>{'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...</td>\n",
       "      <td>{'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>{'word': '민주평화당', 'start_idx': 19, 'end_idx': ...</td>\n",
       "      <td>{'word': '대안신당', 'start_idx': 14, 'end_idx': 1...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>{'word': '광주FC', 'start_idx': 21, 'end_idx': 2...</td>\n",
       "      <td>{'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx...</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...   \n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...   \n",
       "2   2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...   \n",
       "\n",
       "                                      subject_entity  \\\n",
       "0  {'word': '비틀즈', 'start_idx': 24, 'end_idx': 26...   \n",
       "1  {'word': '민주평화당', 'start_idx': 19, 'end_idx': ...   \n",
       "2  {'word': '광주FC', 'start_idx': 21, 'end_idx': 2...   \n",
       "\n",
       "                                       object_entity          label     source  \n",
       "0  {'word': '조지 해리슨', 'start_idx': 13, 'end_idx':...    no_relation  wikipedia  \n",
       "1  {'word': '대안신당', 'start_idx': 14, 'end_idx': 1...    no_relation   wikitree  \n",
       "2  {'word': '한국프로축구연맹', 'start_idx': 34, 'end_idx...  org:member_of   wikitree  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/opt/ml/dataset/train/train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K_IKvemL2kqT"
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "output_texts = []\n",
    "rels = set()\n",
    "rel_cnt = {}\n",
    "for sent, s, o, rel in zip(df.sentence, df.subject_entity, df.object_entity, df.label):\n",
    "    sbj = eval(s)['word']\n",
    "    obj = eval(o)['word']\n",
    "    rels.add(rel)\n",
    "    if rel in rel_cnt:\n",
    "        cnt = rel_cnt[rel]\n",
    "        cnt += 1\n",
    "        rel_cnt[rel] = cnt\n",
    "    else:\n",
    "        rel_cnt[rel] = 1\n",
    "    input_texts.append(sbj + ' - ' + obj + ' [' + rel + ']')\n",
    "    output_texts.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTKnzM3Q6YIV",
    "outputId": "b822a6a1-a9e1-4d15-df76-80a110f701e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32470\n",
      "32470\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(input_texts))\n",
    "print(len(output_texts))\n",
    "print(len(rels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kas-oNF166kQ",
    "outputId": "b948122c-44f6-42d5-9322-e22fa668d5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비틀즈 - 조지 해리슨 [no_relation]\n",
      "〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey Road》에 담은 노래다.\n"
     ]
    }
   ],
   "source": [
    "print(input_texts[0])\n",
    "print(output_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzZqU6Ql7EvM"
   },
   "source": [
    "# 2. Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n2dBjMvp6ojX"
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "referenced_widgets": [
      "aa766e3cca724ac7b03c7eb7a9f1469f",
      "57f3ece2a95348d5b4bb613d55439834",
      "6523bac8e25d454098a534249415052f",
      "da1f448798154db3a8b9f2797695c634",
      "514fee3580674299b60dfd946aec7c53",
      "5ec94aa5826a4abaaecaa05a2cd60789",
      "8f2649e4a9c64dfab27cd7b9f569ac54",
      "5a4263adffbd44b3b77699bf8a548095",
      "e28b532367fa4652a6d9152bfac114cc",
      "d40fa5156e4345f4ac7119df8fd913ec",
      "d9e09866a50e421e8af4c939b3a47ac0",
      "462b8bc7aaf94708b5c27d70d7f8dd0a",
      "3a0d3b0b247b4a63bde1c2df3da6eed0",
      "a7af1817f3784b74b22a45248e829d05",
      "fbca1e3743bb425aa62d12fff9fcabe4",
      "b6016bf27a55486e8d974ed3fa5e14b7",
      "83ed8209b19f435a9a87f4bd26ba8985",
      "5b9d82a43440434bb176799b8352d676",
      "f747f5533bce4ba2b4b643ef7158b7ee",
      "0c0ec53055a2469b9fcf292b95efa35b",
      "63fae3b4dd434bb6b82006c4bc029a87",
      "e64ca505b3994c6981cd6c2575d00e89",
      "b4a5b14f095e4b0d8287a3e96a73fce9",
      "641e7a7c7eb54a8cb48709ac3408d4d6",
      "8354c2f5ad4c4c91b08e1eaf8e958e75",
      "98164fdbde1b47a1a0a69a7b32700988",
      "430462777a0e49b0bea32c226be263d0",
      "0d43e5280b154efdaeba463cb2568637",
      "2b05ac62c5d541e09b639d84f9d7aac8",
      "bd2298e0ab2a4f24adb2e52b61b39abf",
      "9b4abd7a19b1431fb0e0fffbedf76853",
      "67032db5adf743bfbf9eaac4bec04e30",
      "9cbbdd0e7275465f84df0526f57f7369",
      "a56df1ea2dc24097849483468682b52d",
      "d37e3c1f9ee949c7a5f97c0722375e7d",
      "19de366f3d1d44c5b6ed6dc6b540f92d",
      "b8b844540ff646758dc9c1339012919c",
      "b1c5f3add0dc40e48f7eeff75644bdf2",
      "37a898f7fb064c74a166b6d26f50f428",
      "ab4cde29b68b462eac058f64f0e85252",
      "625118e6e10141569629d027824a1252",
      "2385694ce7a948018e64d0b1f0acc6ce",
      "05cc901eb29144fb8133980bae089c69",
      "20c98d696b7042b1a24a1b2c1f4bf211",
      "730b2ac11efc43dfa1a6fbcd01ad6df9",
      "71594b180cfe49048b7caabb753c69a9",
      "30767572fac94a08be6d7c48977c82da",
      "be736850565142d4b3dbc01f2f4a80ec",
      "a1ee0824323b4650ac62ac198057e946",
      "4e4bcd33151940cab613cac766376b8a",
      "6d69e98c899d406ba03da142e7e0afd5",
      "461cadf6a25d446f99a5343ed8d003d9",
      "e98d02dd6de448439968524f9052b1bf",
      "d35d6309c2804d5ebef94fbc894c7b06",
      "2ab3b9798b544567bad8729e3ec910e7"
     ]
    },
    "id": "JyM4-QOx63EV",
    "outputId": "6efce9ef-3f12-481d-afc6-f517f31a3c3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('hyunwoongko/kobart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVYy6WXJ7deM",
    "outputId": "1d31971e-f2fa-41fb-c6c4-1ddd6b1de2a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁비틀',\n",
       " '즈',\n",
       " '▁-',\n",
       " '▁조지',\n",
       " '▁해',\n",
       " '리',\n",
       " '슨',\n",
       " '▁[',\n",
       " 'n',\n",
       " 'o',\n",
       " '_',\n",
       " 're',\n",
       " 'la',\n",
       " 'tion',\n",
       " ']']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(input_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tHaQezn97NM6"
   },
   "outputs": [],
   "source": [
    "additional_tokens = []\n",
    "for rel in rels:\n",
    "    additional_tokens.append('[' + rel + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUdslTf2N6fl"
   },
   "source": [
    "데이터의 relation들을 special token으로 추가합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u0jhh-vO7UFK"
   },
   "outputs": [],
   "source": [
    "added_token_num = tokenizer.add_special_tokens({'additional_special_tokens':additional_tokens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SnF0oKFe7jPE",
    "outputId": "1cd0e232-2753-4320-8e9e-624030e8e5f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁비틀', '즈', '▁-', '▁조지', '▁해', '리', '슨', '▁', '[no_relation]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(input_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFYTczYd7kD_",
    "outputId": "cc5b61de-47eb-41cb-d5a6-b79d122d6187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(added_token_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhOkULMFOVk6"
   },
   "source": [
    "기존 vocab에 임의로 token들을 추가했으니, 모델사이즈도 반드시 늘려줘야겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2797c5056baf4d51be2ce0b52ddf3cb5",
      "3521a8f21b364bd893ee8add695855dd",
      "74be10b2598349d4ba8990ead111a8d2",
      "e010526c062c41dfacbf4ce5003db6fa",
      "3b777d2f2e76447ca1892b102c2f2ed0",
      "f8edd91437384be5a7d29365d068bea2",
      "6e063852835d4a9389f2bd36a58c430c",
      "91a7569ba6614a5b960d6c70165ed086",
      "f8386756ec514b379a2b571dc2e40be7",
      "c3f492b81f764181b7748d681b6f113f",
      "d890665d18c8480f9f49b61df290324b"
     ]
    },
    "id": "hktld9cD7mD6",
    "outputId": "02ea80e3-3157-4f02-d080-27d37471869f"
   },
   "outputs": [],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained('hyunwoongko/kobart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZzlhvI07vSB",
    "outputId": "df0d49cb-8e51-40ba-b4a4-47683417166d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30030, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(tokenizer.vocab_size + added_token_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGpvqE1c74Tr",
    "outputId": "f3a6473f-6272-433f-a4b5-ca48287904f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30030, 768)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30030, 768)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30030, 768)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30030, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYFC01CT78kw"
   },
   "source": [
    "# 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OlML3Dp283_E"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, BatchEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jnsPXT1_9lYC"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model = model,\n",
    "    padding = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-vxBJDCU75yn"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DummySeq2SeqDataset(Dataset):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerFast):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.src_texts = input_texts\n",
    "        self.tgt_texts = output_texts\n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "    def __getitem__(self, index: int) -> BatchEncoding:\n",
    "        src_text = self.src_texts[index].strip()\n",
    "        tokenized_src_text = self.tokenizer.encode(src_text)[0:512-4]\n",
    "        src_text = '<s>' + self.tokenizer.decode(tokenized_src_text) + '</s>'\n",
    "\n",
    "        tgt_text = self.tgt_texts[index].strip()\n",
    "        tokenized_tgt_text = self.tokenizer.encode(tgt_text)[0:512-4]\n",
    "        tgt_text = '<s>' + self.tokenizer.decode(tokenized_tgt_text) + '</s>'\n",
    "        \n",
    "        return self.tokenizer.prepare_seq2seq_batch(\n",
    "            src_text, tgt_text, truncation=True, max_length=512, return_token_type_ids=False, padding=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SMUtz9aW-6aV"
   },
   "outputs": [],
   "source": [
    "train_dataset = DummySeq2SeqDataset(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s913KBlQ_EHe"
   },
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Laioo-QP81GE",
    "outputId": "d98b5fe8-cf3c-468a-d52e-0fb8c4f6f679"
   },
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='./re_generator',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=2000,\n",
    "    save_total_limit=4,\n",
    "    logging_steps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IqDP6TLC-_1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "F36kwFl5_ZrO",
    "outputId": "ca074b9e-0c2b-467b-b04e-9253f423a8b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 32470\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 16236\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdayday\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./re_generator</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/dayday/huggingface\" target=\"_blank\">https://wandb.ai/dayday/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/dayday/huggingface/runs/2dxj85io\" target=\"_blank\">https://wandb.ai/dayday/huggingface/runs/2dxj85io</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/wandb/run-20211001_083953-2dxj85io</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3365: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16236' max='16236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16236/16236 35:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.881200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.474600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.365500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.330800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.293500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.274700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>3.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>3.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>3.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>3.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.776600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.793900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.806800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>2.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>2.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>2.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.758200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>2.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.795800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.789300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>2.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>2.628300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>2.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>2.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>2.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>2.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>2.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>2.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>2.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>2.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>2.419600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>2.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>2.413600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>2.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>2.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>2.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>2.150500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>2.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>2.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.170700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>2.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>2.228300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>2.167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>2.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.244300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>2.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>2.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>2.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>2.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>2.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>2.225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>2.196900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>2.219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>2.182500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./re_generator/checkpoint-2000\n",
      "Configuration saved in ./re_generator/checkpoint-2000/config.json\n",
      "Model weights saved in ./re_generator/checkpoint-2000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3365: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "Saving model checkpoint to ./re_generator/checkpoint-4000\n",
      "Configuration saved in ./re_generator/checkpoint-4000/config.json\n",
      "Model weights saved in ./re_generator/checkpoint-4000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3365: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "Saving model checkpoint to ./re_generator/checkpoint-6000\n",
      "Configuration saved in ./re_generator/checkpoint-6000/config.json\n",
      "Model weights saved in ./re_generator/checkpoint-6000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3365: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "Saving model checkpoint to ./re_generator/checkpoint-8000\n",
      "Configuration saved in ./re_generator/checkpoint-8000/config.json\n",
      "Model weights saved in ./re_generator/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to ./re_generator/checkpoint-10000\n",
      "Configuration saved in ./re_generator/checkpoint-10000/config.json\n",
      "Model weights saved in ./re_generator/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [re_generator/checkpoint-2000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3365: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and the tokenizer under the `as_target_tokenizer` context manager to prepare\n",
      "your targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "with tokenizer.as_target_tokenizer():\n",
      "    labels = tokenizer(tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16236, training_loss=2.6974834095348013, metrics={'train_runtime': 2125.7314, 'train_samples_per_second': 61.099, 'train_steps_per_second': 7.638, 'total_flos': 7738997824696320.0, 'train_loss': 2.6974834095348013, 'epoch': 4.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt14IMwl_bfc",
    "outputId": "ec33edc2-5db5-4309-92fb-30e00fbe5a48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to re_generator_final_model\n",
      "Configuration saved in re_generator_final_model/config.json\n",
      "Model weights saved in re_generator_final_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('re_generator_final_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ppVIqdAscldl",
    "outputId": "6a5b35e2-e4a3-4ad0-bf13-8796cd3b86fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zTtm7O0fIpAt"
   },
   "outputs": [],
   "source": [
    "! cp -r re_generator_final_model drive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDBwWpgbAw4m"
   },
   "source": [
    "# 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_jvOWI6DktH",
    "outputId": "6537db2e-6933-4434-a629-28ba47feb754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org:political/religious_affiliation\n",
      "per:place_of_death\n",
      "org:founded_by\n",
      "per:siblings\n",
      "org:product\n",
      "org:members\n",
      "per:place_of_birth\n",
      "org:place_of_headquarters\n",
      "org:alternate_names\n",
      "per:children\n",
      "per:origin\n",
      "per:title\n",
      "org:top_members/employees\n",
      "per:spouse\n",
      "per:parents\n",
      "per:alternate_names\n",
      "org:dissolved\n",
      "no_relation\n",
      "per:colleagues\n",
      "org:founded\n",
      "org:member_of\n",
      "per:schools_attended\n",
      "per:other_family\n",
      "per:employee_of\n",
      "org:number_of_employees/members\n",
      "per:product\n",
      "per:date_of_death\n",
      "per:place_of_residence\n",
      "per:date_of_birth\n",
      "per:religion\n"
     ]
    }
   ],
   "source": [
    "for rel in rels:\n",
    "    print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UvE11HHfJTWP"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vuUmVlbIMVKM",
    "outputId": "90ae17f1-1097-4802-e2a4-f37f7e67c374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "unk_token_id = tokenizer.encode('<unk>')\n",
    "print(unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "3u5eGISrAX8J"
   },
   "outputs": [],
   "source": [
    "def get_sent(sbj, obj, rel):\n",
    "    if rel not in rels:\n",
    "        return \"not defined relation\"\n",
    "    text = '<s>' + sbj + ' - ' + obj + ' [' + rel + ']</s>'\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    input_ids = input_ids.unsqueeze(0).to('cuda')\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        eos_token_id=1, # </s>\n",
    "        max_length=130,\n",
    "        top_p=0.8,\n",
    "        top_k=10,\n",
    "        num_return_sequences=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True,\n",
    "        bad_words_ids=[unk_token_id]\n",
    "    )\n",
    "\n",
    "    result = []\n",
    "    for output in outputs:\n",
    "        output = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        result.append(output)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>2893</td>\n",
       "      <td>문하시중 이자연의 조카이고 인예왕후, 인경현비, 인절현비와는 사촌간이다.</td>\n",
       "      <td>{'word': '인절현비', 'start_idx': 27, 'end_idx': 3...</td>\n",
       "      <td>{'word': '이자연', 'start_idx': 5, 'end_idx': 7, ...</td>\n",
       "      <td>per:other_family</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25844</th>\n",
       "      <td>25844</td>\n",
       "      <td>1년 후, 바이에른은 전설적인 오스트리아인 감독 에른스트 하펠이 이끄는 함부르크 S...</td>\n",
       "      <td>{'word': '에른스트 하펠', 'start_idx': 27, 'end_idx'...</td>\n",
       "      <td>{'word': '오스트리아', 'start_idx': 17, 'end_idx': ...</td>\n",
       "      <td>per:origin</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17759</th>\n",
       "      <td>17759</td>\n",
       "      <td>그러다가 1949년 6월 6일 이승만 대통령과 신성모 내무부 장관의 사주를 받은 친...</td>\n",
       "      <td>{'word': '신성모', 'start_idx': 26, 'end_idx': 28...</td>\n",
       "      <td>{'word': '이승만', 'start_idx': 17, 'end_idx': 19...</td>\n",
       "      <td>per:colleagues</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>10515</td>\n",
       "      <td>무라트 1세의 아들 바예지드 1세는 1396년에 불가리아 북부에서 니코폴리스 전투를...</td>\n",
       "      <td>{'word': '바예지드 1세', 'start_idx': 11, 'end_idx'...</td>\n",
       "      <td>{'word': '무라트 1세', 'start_idx': 0, 'end_idx': ...</td>\n",
       "      <td>per:parents</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12680</th>\n",
       "      <td>12680</td>\n",
       "      <td>실제로 남한 쪽에서는 남조선로동당·근로인민당 등 좌익계열 정당뿐 아니라 한국독립당·...</td>\n",
       "      <td>{'word': '박헌영', 'start_idx': 79, 'end_idx': 81...</td>\n",
       "      <td>{'word': '조선로동당', 'start_idx': 13, 'end_idx': ...</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16401</th>\n",
       "      <td>16401</td>\n",
       "      <td>1983년 한국 프로야구(KBO)의 삼미에 입단하면서 장명부라는 등록명을 사용했다.</td>\n",
       "      <td>{'word': '한국 프로야구', 'start_idx': 6, 'end_idx':...</td>\n",
       "      <td>{'word': 'KBO', 'start_idx': 14, 'end_idx': 16...</td>\n",
       "      <td>org:alternate_names</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13741</th>\n",
       "      <td>13741</td>\n",
       "      <td>최남곤 유안타증권 연구원은 “지난달 30일 자로 과학기술정보통신부가 SK브로드밴드의...</td>\n",
       "      <td>{'word': 'SK브로드밴드', 'start_idx': 38, 'end_idx'...</td>\n",
       "      <td>{'word': 'SK텔레콤', 'start_idx': 84, 'end_idx': ...</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>19987</td>\n",
       "      <td>화순군(군수 구충곤)이 신종 코로나바이러스 감염증(코로나19) 장기화로 어려움을 겪...</td>\n",
       "      <td>{'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...</td>\n",
       "      <td>{'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>5601</td>\n",
       "      <td>시애틀 레인의 감독을 역임하고 있던 로라 하비는 킴 리틀의 시애틀 레인 이적을 주선...</td>\n",
       "      <td>{'word': '킴 리틀', 'start_idx': 27, 'end_idx': 3...</td>\n",
       "      <td>{'word': '아스널', 'start_idx': 82, 'end_idx': 84...</td>\n",
       "      <td>per:employee_of</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>2678</td>\n",
       "      <td>아일랜드 공화국은 1919년 1월 그레이트브리튼으로부터의 독립을 선언한 혁명정체다.</td>\n",
       "      <td>{'word': '아일랜드', 'start_idx': 0, 'end_idx': 3,...</td>\n",
       "      <td>{'word': '공화국', 'start_idx': 5, 'end_idx': 7, ...</td>\n",
       "      <td>org:political/religious_affiliation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           sentence  \\\n",
       "2893    2893           문하시중 이자연의 조카이고 인예왕후, 인경현비, 인절현비와는 사촌간이다.   \n",
       "25844  25844  1년 후, 바이에른은 전설적인 오스트리아인 감독 에른스트 하펠이 이끄는 함부르크 S...   \n",
       "17759  17759  그러다가 1949년 6월 6일 이승만 대통령과 신성모 내무부 장관의 사주를 받은 친...   \n",
       "10515  10515  무라트 1세의 아들 바예지드 1세는 1396년에 불가리아 북부에서 니코폴리스 전투를...   \n",
       "12680  12680  실제로 남한 쪽에서는 남조선로동당·근로인민당 등 좌익계열 정당뿐 아니라 한국독립당·...   \n",
       "16401  16401     1983년 한국 프로야구(KBO)의 삼미에 입단하면서 장명부라는 등록명을 사용했다.   \n",
       "13741  13741  최남곤 유안타증권 연구원은 “지난달 30일 자로 과학기술정보통신부가 SK브로드밴드의...   \n",
       "19987  19987  화순군(군수 구충곤)이 신종 코로나바이러스 감염증(코로나19) 장기화로 어려움을 겪...   \n",
       "5601    5601  시애틀 레인의 감독을 역임하고 있던 로라 하비는 킴 리틀의 시애틀 레인 이적을 주선...   \n",
       "2678    2678     아일랜드 공화국은 1919년 1월 그레이트브리튼으로부터의 독립을 선언한 혁명정체다.   \n",
       "\n",
       "                                          subject_entity  \\\n",
       "2893   {'word': '인절현비', 'start_idx': 27, 'end_idx': 3...   \n",
       "25844  {'word': '에른스트 하펠', 'start_idx': 27, 'end_idx'...   \n",
       "17759  {'word': '신성모', 'start_idx': 26, 'end_idx': 28...   \n",
       "10515  {'word': '바예지드 1세', 'start_idx': 11, 'end_idx'...   \n",
       "12680  {'word': '박헌영', 'start_idx': 79, 'end_idx': 81...   \n",
       "16401  {'word': '한국 프로야구', 'start_idx': 6, 'end_idx':...   \n",
       "13741  {'word': 'SK브로드밴드', 'start_idx': 38, 'end_idx'...   \n",
       "19987  {'word': '화순군', 'start_idx': 0, 'end_idx': 2, ...   \n",
       "5601   {'word': '킴 리틀', 'start_idx': 27, 'end_idx': 3...   \n",
       "2678   {'word': '아일랜드', 'start_idx': 0, 'end_idx': 3,...   \n",
       "\n",
       "                                           object_entity  \\\n",
       "2893   {'word': '이자연', 'start_idx': 5, 'end_idx': 7, ...   \n",
       "25844  {'word': '오스트리아', 'start_idx': 17, 'end_idx': ...   \n",
       "17759  {'word': '이승만', 'start_idx': 17, 'end_idx': 19...   \n",
       "10515  {'word': '무라트 1세', 'start_idx': 0, 'end_idx': ...   \n",
       "12680  {'word': '조선로동당', 'start_idx': 13, 'end_idx': ...   \n",
       "16401  {'word': 'KBO', 'start_idx': 14, 'end_idx': 16...   \n",
       "13741  {'word': 'SK텔레콤', 'start_idx': 84, 'end_idx': ...   \n",
       "19987  {'word': '구충곤', 'start_idx': 7, 'end_idx': 9, ...   \n",
       "5601   {'word': '아스널', 'start_idx': 82, 'end_idx': 84...   \n",
       "2678   {'word': '공화국', 'start_idx': 5, 'end_idx': 7, ...   \n",
       "\n",
       "                                     label     source  \n",
       "2893                      per:other_family  wikipedia  \n",
       "25844                           per:origin  wikipedia  \n",
       "17759                       per:colleagues  wikipedia  \n",
       "10515                          per:parents  wikipedia  \n",
       "12680                          no_relation  wikipedia  \n",
       "16401                  org:alternate_names  wikipedia  \n",
       "13741                        org:member_of   wikitree  \n",
       "19987            org:top_members/employees   wikitree  \n",
       "5601                       per:employee_of  wikipedia  \n",
       "2678   org:political/religious_affiliation  wikipedia  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "generated = []\n",
    "for sbj, obj, label in tqdm(zip(test_df.subject_entity, test_df.object_entity, test_df.label)):\n",
    "    generated.append(get_sent(eval(sbj)['word'],eval(obj)['word'],label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sbj   :  인절현비\n",
      "original obj   :  이자연\n",
      "original label :  per:other_family\n",
      "original sentence:  문하시중 이자연의 조카이고 인예왕후, 인경현비, 인절현비와는 사촌간이다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 인승군 이세공 연경의 부인 이자연과 혼인하여 승문원, 예문관, 예서사화를 비롯하여 의경태후의 부인 인절현비, 영조계의 시조인 명현승, 영조의 손자 이자연, 예덕후의 며느리이며 후궁이다.\n",
      "[2] : 이자 인조의 아들 이자연은 인절현비를 시해하고 사형이 언도된 공(公)이었는데 이것은 요절(堯節)이라 한다.\n",
      "[3] : 신빈 이씨의 아내 이자연은 인절현비의 조카이자 효종이다.\n",
      "[4] : 인 후일 경연왕후가 한학을 할 때 이자연의 후궁이 되어서, 영조와 인촌현비, 인효현비는 그의 아들이고 인절현비의 동생이고, 이자연이 그의 누이이다.\n",
      "[5] : 이자왕(王)을 폐하고 인숙현비의 측근인 이자연을 왕으로 추대하여 문신을 차출하고, 관직과 직위를 나누어 인현왕후를 폐위시키고, 문신 이이를 성종의 종으로 삼았다.\n"
     ]
    }
   ],
   "source": [
    "origin = test_df.iloc[0]\n",
    "print('original sbj   : ', eval(origin['subject_entity'])['word'])\n",
    "print('original obj   : ',eval(origin['object_entity'])['word'])\n",
    "print('original label : ',origin['label'])\n",
    "print('original sentence: ', origin['sentence'])\n",
    "print('-'*100)\n",
    "print('generated sentence')\n",
    "for i in range(5):\n",
    "    print(f'[{i+1}] : {generated[0][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  인절현비\n",
      "original obj   :  이자연\n",
      "original label :  per:other_family\n",
      "original sentence:  문하시중 이자연의 조카이고 인예왕후, 인경현비, 인절현비와는 사촌간이다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 인승군 이세공 연경의 부인 이자연과 혼인하여 승문원, 예문관, 예서사화를 비롯하여 의경태후의 부인 인절현비, 영조계의 시조인 명현승, 영조의 손자 이자연, 예덕후의 며느리이며 후궁이다.\n",
      "[2] : 이자 인조의 아들 이자연은 인절현비를 시해하고 사형이 언도된 공(公)이었는데 이것은 요절(堯節)이라 한다.\n",
      "[3] : 신빈 이씨의 아내 이자연은 인절현비의 조카이자 효종이다.\n",
      "[4] : 인 후일 경연왕후가 한학을 할 때 이자연의 후궁이 되어서, 영조와 인촌현비, 인효현비는 그의 아들이고 인절현비의 동생이고, 이자연이 그의 누이이다.\n",
      "[5] : 이자왕(王)을 폐하고 인숙현비의 측근인 이자연을 왕으로 추대하여 문신을 차출하고, 관직과 직위를 나누어 인현왕후를 폐위시키고, 문신 이이를 성종의 종으로 삼았다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  에른스트 하펠\n",
      "original obj   :  오스트리아\n",
      "original label :  per:origin\n",
      "original sentence:  1년 후, 바이에른은 전설적인 오스트리아인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 에른스트 하펠(Rernst Hätchel, 1923-1954, 1947–70)은 오스트리아의 작곡가, 작사가, 음악가, 피아니스트이다.\n",
      "[2] : 에에슬리 에른스트 하펠은 오스트리아에서 활동하던 시절 그의 동료인 에버튼 더비필드에서 주로 활동했다.\n",
      "[3] : 에 에른스트 하펠(1990년 5월 21일 ~ 2020년 7월 22일)은 오스트리아의 배우이자 가수이다.\n",
      "[4] : 펠 오스트리아 축구 대표팀이 크리스티안 페텔, 에른스트 하펠에 이어 베테랑 골키퍼 3명을 영입하면서 유럽 무대에 진출했다.\n",
      "[5] : 에르난 D. 토레(Fernand Dantto Torrekt), 에른스트 하펠(Ernst Harfelle, 1886년 4월 20일~1971년 1월 5일)과 함께 오스트리아 빈에 위치한 SSG FC에서 데뷔하였으며 이 공격수로 1995-2000시즌부터 2008-09시즌까지 활약하였다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  신성모\n",
      "original obj   :  이승만\n",
      "original label :  per:colleagues\n",
      "original sentence:  그러다가 1949년 6월 6일 이승만 대통령과 신성모 내무부 장관의 사주를 받은 친일 경찰이 반민특위 사무실을 습격하는 사건 발생 후 반민특위가 사실상 무력화되면서 서울 마포형무소에 구금되었던 하판락은 서울에서 3회, 부산에서 1회 등 모두 4차 공판을 거쳐 최종 무혐의로 풀려났다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 이승만은 친정을 반대했던 신성모를 이승만이 임시정부에서 제지하고 나가면서 이승만과 사이가 틀어졌다.\n",
      "[2] : 그러나만은 신성모를 이승만계 미국인 외교관으로 임용했다가, 신성모가 임시의정원위원직에서 제명된 것과 관련하여 이승만의 누나를 미국으로 유학 보내는 등 갖가지 음모를 저질렀으나 이승만은 미국인의 사생활에 착안하여 안중근과 수시로 교감을 하며 적극적으로 반탁운동을 전개했다.\n",
      "[3] : 이승9년을 지지한 이승만과 그를 지지하는 신성모, 이승만의 특명으로 간행한 이범석 등과 같은 세력들은 4월 16일 이승만을 성접했다.\n",
      "[4] : 그는만준 선생에게 \"만약 한국 전쟁이 일어나기만 한 내가 외국으로 탈출하면 한국인과 북한인 사이에 무슨 차이가 있을 것이며, 이승만은 북한인과 한국인을 적대시하게 되고, 한국군을 북한으로부터 보호받을 수 없도록 방치하고 있다\"고 설득하여 신성모를 이승만 대통령에 임명되게 했다.\n",
      "[5] : 1939년 1월 9일 이승만, 신성모, 허정, 한용운 등은 대한민국 임시 정부의 수립을 환영하는 성명을 발표하고 국민과 함께 \"정부와 이승만이 일치하는 정책을 수립하고 그 출발을 국민 앞에서 빛내  내야 한다.\"고 촉구했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  바예지드 1세\n",
      "original obj   :  무라트 1세\n",
      "original label :  per:parents\n",
      "original sentence:  무라트 1세의 아들 바예지드 1세는 1396년에 불가리아 북부에서 니코폴리스 전투를 벌여, 이 전투에서 헝가리 왕국을 필두로 한 십자군을 격파, 오히려 영토를 더 크게 넓혔다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 당시961년 무라트 1세 후기의 무술왕 바예지드 1세의 아들로서 태어났다.\n",
      "[2] : 무예지드 1세의 아들 무라트 1세는 촐라에 입적되어, 무이크와 대적하였다.\n",
      "[3] : 13라트 1세 국왕(재위: 1227년 - 1248년)은 제9대 술탄(마르세스 1세, 무라디 5세, 바예지드 1세의 아들)으로서 나바라 왕국의 영토를 넓히고 대외관계를 안정시켰다.\n",
      "[4] : 페르라흐 7세 때 무라트 1세의 조카이자 바예지드 1세 왕궁의 총지휘를 맡았던 술탄이 이 바예를 이기고 누나인 바그다드에게 쿠베르탱탱 왕국을 넘기기 위해, 이베리아 반도 서남쪽의 알제리를 등지고 동유럽 서북부 지역들을 정복하였으며, 1392년에는 안나푸르나와의 연합을 통해 영토를 확장했으며, 1382년에 아바스족과 바비족이 연합하여 바바리아를 통치하였다.\n",
      "[5] : 또한샤트 왕조의 무라트 1세의 아들 바예지드 1세를 왕으로 추대하고 자신의 아들 고드바흐가 추방되기 전까지 그의 통치 기간 동안 통치하면서 바레시아 강 남안 지역을 통치하였다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  박헌영\n",
      "original obj   :  조선로동당\n",
      "original label :  no_relation\n",
      "original sentence:  실제로 남한 쪽에서는 남조선로동당·근로인민당 등 좌익계열 정당뿐 아니라 한국독립당·민족자주연맹 등 우익계열 정당들도 참여하였을 뿐만 아니라, 박헌영·백남운·김구·김규식·조소앙 등 명망있는 좌익 및 우익 인사들도 참석했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 당시 5월에는 조선로동당 중앙위 부위원장에 김옥선(金玉선진), 조선인민군 총정치국장 박헌영(朴憲永) 등을 영입했다.\n",
      "[2] : 박6년 12월 10일에 조선로동당 최고상무로 재상임부장으로 내정되어 박헌영의 추천으로 정치국 상무위원이 되었다.\n",
      "[3] : 박로소녀상은 1937년 조선공산당을 개편한 후 박헌영을 총비서로 하였으나, 1939년 박승희가 1944년 12월 23일 소련공산에 흡수되어 조선로동당으로 이름을 바꾸었다.\n",
      "[4] : 조선헌법재판소의 박헌영 재판관과 조선인민군, 당중앙위원들의 항의가 모두 합헌이며, 박만수 의사의 재판관이 조선로동당의 재판관에 임명된 것을 합당한 처사라고 믿는 경우 파기환수가 정당 정치에 복귀할 수 있다는 주장까지 제기되었다.\n",
      "[5] : 박로호 부인의 조선로동당 제10차 대회 출전을 위해 박헌영, 박세일 부부 등 중국 내 5인이 국내 국내로 입국하였으나 모두 중화인민공화국 정부로 송환, 출국하였다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  한국 프로야구\n",
      "original obj   :  KBO\n",
      "original label :  org:alternate_names\n",
      "original sentence:  1983년 한국 프로야구(KBO)의 삼미에 입단하면서 장명부라는 등록명을 사용했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 한국에서는 1960년에 KBO 리그를 열었고 이후 한국 시리즈에서 한국 프로야구 한국시리즈에서 우승한 이듬해인 1967년에 일본 시리즈에서도 우승하였다.\n",
      "[2] : 그는4년을 선수생활을 하면서 한국 프로야구(KBO) 신인 드래프트에 지원했고 한국 야구에서 손꼽히는 실력인 투수 한선수(삼성 라이온즈)가 되어 1986년에 KBO 신인상에 4차례나 수상했다.\n",
      "[3] : 한국 한국 프로야구(KBO) 역대 역대 최고 승무패 기록을 보유했던 1986년과 1995년 최다승 기록을 갖고 있었던 1995년의 기록도 갖고 있다.\n",
      "[4] : 현재 프로야구에서는 현재 KBO의 산하 팀인 삼성 라이온즈의 내야진을 맡고 있으며, 현재 연고 구단인 kt 위즈가 현재 운영 중이다.\n",
      "[5] : 김4년에 걸쳐 KBO 한국 시리즈로 우승과 준 플레이오프 준우승을 모두 경험한 양승호 전 롯데 자이언츠 감독은 \"선수들 스스로 한국에서의 제구력이 대단하다는 것을 보여줬다\"고 평가받기도 했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  SK브로드밴드\n",
      "original obj   :  SK텔레콤\n",
      "original label :  org:member_of\n",
      "original sentence:  최남곤 유안타증권 연구원은 “지난달 30일 자로 과학기술정보통신부가 SK브로드밴드의 티브로드 M&A(인수·합병)에 대한 조건부 인가를 결정했다”라며 “SK텔레콤 입장에서는 향후 방통위 승인 이후 연결 범위 확대 효과를 얻게 될 전망”이라고 분석했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 그는 연구원은 “지난해 9월 KT가 지상파, 유선방송, 위성방송 사업자로 NAVA에 가입한 데 이어 KT, LG유플러스로 분리되면서 각 방송사는 통신사업자로 나뉘면서 각 통신사가 제공하는 콘텐츠와 콘텐츠의 시장지위도 모두 하락했다. 통신업종은 SK브로드밴드의 통신비중이 높기 때문에 경쟁 심화와 수익성 악화를 막기 위한 수익성 높은 광고 단가 인하 등 외형 변수를 흡수하기 위한 조치를 취했다. 또한 경쟁사와의 협업을 통해 경쟁력있는 콘텐츠 제작을 지원함으로써 통신 3사의 통신 경쟁력 향상을 도모했다. 이는 KT 전체 가입자 수도 지속적으로 상승하게 됐다”며 “통신사별 광고단가격 차이가 여전히 존재하는 상황에서 향후 수익성 및 고객가치 제고에 대한 고민이 지속적으로 제기될 것으로 보인다”고 설명했다.\n",
      "[2] : 김 1월 8일 출범식에서 송 사장은 “지난해 SK브로드밴드로부터 500만 이상의 주식을 받았고 향후 3사 SK텔레콤의 지분을 인수하는 것을 검토 중”이라고 밝혀 통신주력 지분(CD)로 SK텔레콤 지분을 전량 매각할 것임을 시사했다.\n",
      "[3] : SK텔레콤주유소매연합(대표 오성택)은 지난 5일 양일간 양촌읍 행정복지센터에 SK텔레콤과 SK브로드밴드가 공동 주최한 ‘텔레콤의 미래, 한바이스’ 수탁 기념 행사에서 이낙연 총수 일행과 함께 SK텔레콤, SK이노베이션, SK텔레콤의 파트너사인 와이브로, SK텔레콤 협력회사인 SK텔레콤에 각각 3개의 상패를 전달했다고 7일 밝혔다.\n",
      "[4] : 김정일 IBK투자증권 연구원은 “SK루페이는 올해 유선 통신사 중 유일하게 유·불리한 판관비를 절감하지 않고서도 통신 3사 가운데 유일하게 지난해 영업이익 기준 이익 성장을 기록했다”며 “올해 유-헬스케어 플랫폼 매출 증가와 더불어 NAVER와 T맵 가입 증가에 따른 통신비 절감, BATT의 실적 호조를 바탕으로 SK텔레콤의 전체 매출액(ANLCI 대비 4.5~4.8%)도 견조하게 유지될 것으로 전망된다”라고 설명했다.\n",
      "[5] : 지난, SK텔레콤은 유선 통신이 아닌 다른 통신 3사 및 유·초소들의 합병을 SK텔레콤의 자회사 SK브로드밴드로의 완전 전환 이후 SK텔레콤만의 이동통신 서비스로 전환하겠다고 공시했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  화순군\n",
      "original obj   :  구충곤\n",
      "original label :  org:top_members/employees\n",
      "original sentence:  화순군(군수 구충곤)이 신종 코로나바이러스 감염증(코로나19) 장기화로 어려움을 겪고 있는 지역 외식업소를 돕기 위해 ‘공직자 점심 나드리 day’를 운영한다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 화순군(군수 구충곤)이 지난 2일 화천읍 사동리 한탄강에 화창모임을 실시해 연찬회를 가졌다.\n",
      "[2] : 화순군이(군수 구충곤)이 농촌의 생육을 돕기 위한 대책의 하나로 벼 20kg 이상(160mm) 농기계 구입 시 100만원을 화살포기 주민을 대상으로 지급하고 있다.\n",
      "[3] : 화순군(군수 구충곤)은 지난 20일 열린 2019년도 전라남도 시.도 시·군 종합경기장을 찾아 종합 경기장 시립화장실 건립 등 지역 현안사업에 대한 적극적인 협조를 당부했다.\n",
      "[4] : 화순군(군수 구충곤)이 군민 아이디어를 공모한 결과 ‘찾아가는 청년 창업 아이디어 공모전’ 우수상을 수상했다.\n",
      "[5] : 화순군(군수 구충곤)이 지난 5일 화천군청 재난종합상황실에서 2020년도 하반기 화천힐링힐링센터 개관이 완료됐다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  킴 리틀\n",
      "original obj   :  아스널\n",
      "original label :  per:employee_of\n",
      "original sentence:  시애틀 레인의 감독을 역임하고 있던 로라 하비는 킴 리틀의 시애틀 레인 이적을 주선했는데 로라 하비는 시애틀 레인의 감독으로 임명되기 1년 전까지 아스널의 감독을 맡았다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 손흥 킴 리틀은 아스널에서 프리미어리그 데뷔를 했다.\n",
      "[2] : 201킴 리틀은 잉글랜드 프리미어리그 첼시에서 아스널로 이적하여 잉글랜드 무대에 데뷔하였고, 2004-04 시즌 챔피언스리그 우승 팀인 애슬레틱과의 UEFA 챔피언스리그 결승에서 우승 하였으나 결승전에서 승부차기에서 패하면서 리그 최하위를 기록하였다.\n",
      "[3] : 아스 4월 7일, 그는 아스널의 세비야의 킴 리틀 감독에게 자신의 첫 번째 트레블을 맡겼다.\n",
      "[4] : 2011년킴 리틀의 부상 치료를 위해 아스널로 복귀하였고, 킴 에레야는 아스톤 빌라가 보낸 선수단의 보호하에 나갔고, 아스날은 그의 복귀를 승인했다.\n",
      "[5] : 널널은 현재 주전 공격진인 킴 리틀과 아포스 더비를 이어오고 있다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  아일랜드\n",
      "original obj   :  공화국\n",
      "original label :  org:political/religious_affiliation\n",
      "original sentence:  아일랜드 공화국은 1919년 1월 그레이트브리튼으로부터의 독립을 선언한 혁명정체다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 당시 공화국의 국가주의자는 아일랜드를 침략하여, 영국군에게 총격을 당해 전멸되었으며, 이 후 아일랜드가 영국 식민지로 전락하였음을 증명하였다.\n",
      "[2] : 아일랜드 공화국에서는 아일랜드 왕국과 스코틀랜드 공화국을 포함해서 모든 주요 영토 안의 민족을 분리시켰다.\n",
      "[3] : 18 전쟁 시기는 아일랜드 사회주의 공화국 (UNDP)을 둘러싼 일련의 갈등에서 기인한다.\n",
      "[4] : 이러한 민주적 절차에 따라 아일랜드 공화국은 영국령 리가에서 독립했다.\n",
      "[5] : 북4년에는 루마니아와 포르투갈이 합당하여 아일랜드 공화국이 수립되었으며 루마는 포르투갈의 침공으로부터 완전히 해방되었다.\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    origin = test_df.iloc[idx]\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print('original sbj   : ', eval(origin['subject_entity'])['word'])\n",
    "    print('original obj   : ',eval(origin['object_entity'])['word'])\n",
    "    print('original label : ',origin['label'])\n",
    "    print('original sentence: ', origin['sentence'])\n",
    "    print('-'*100)\n",
    "    print('generated sentence')\n",
    "    for i in range(5):\n",
    "        print(f'[{i+1}] : {generated[idx][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "generated = []\n",
    "for sbj, obj, label in tqdm(zip(test_df.subject_entity, test_df.object_entity, test_df.label)):\n",
    "    generated.append(get_sent(eval(sbj)['word'],eval(obj)['word'],label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  인절현비\n",
      "original obj   :  이자연\n",
      "original label :  per:other_family\n",
      "original sentence:  문하시중 이자연의 조카이고 인예왕후, 인경현비, 인절현비와는 사촌간이다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 또한연과 인현왕후, 인절현비(仁顯顯vet)의 아들이며 인조의 동생이며 태조의 친정아버지이다.\n",
      "[2] : 한편연(李容淵, ~)은 조선 세종 때 인조(세종)의 장남이자 인현의 직계비로, 인조의 차남이며, 인절현비의 동생인 이자연의 차녀이다.\n",
      "[3] : 14시 27분, 이자연은 인절현비의 둘째 아들로 태어났으며, 인조는 그의 형 이자연의 딸이자 사도세자의 외숙부였다.\n",
      "[4] : 인연왕후는 인절현비(李慈賢妃), 의종후(義宗后) 등과 혼인하였는데, 이 때 이자연은 인연이 없었다.\n",
      "[5] : 14연왕비 이자연의 사돈이며 인현왕후, 인혜왕후의 사촌동생이다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  에른스트 하펠\n",
      "original obj   :  오스트리아\n",
      "original label :  per:origin\n",
      "original sentence:  1년 후, 바이에른은 전설적인 오스트리아인 감독 에른스트 하펠이 이끄는 함부르크 SV와 DFB-포칼 결승에서 만났다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 에 오스트리아의 에른스트 하펠(Ernst Happel, 1963년 8월 30일 ~)은 오스트리아 출신의 축구 선수로, 현재 리그1의 FC 바이에른 뮌헨에서 스트라이커로 활약하고 있다.\n",
      "[2] : 에의 에른스트 하펠은 1969년 오스트리아의 축구 선수로, 그는 1972년에 오스트리아로 돌아와 리그에서 활약하였다.\n",
      "[3] : 오스트리아 오스트리아의 에른스트 하펠은 그의 경력에 대한 이단적인 평가를 내려야 했다.\n",
      "[4] : 에 오스트리아의 에른스트 하펠이 영입한 헤타페는 독일 축구 국가대표팀과 UEFA 유로파리그 예선을 같이 치른다.\n",
      "[5] : 에르빈 에른스트 하펠이 지휘하는 오스트리아의 프로 축구 팀에서 미드필더로 뛰는 동안, 그는 프리메라리가에서 맹활약을 펼쳤다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  신성모\n",
      "original obj   :  이승만\n",
      "original label :  per:colleagues\n",
      "original sentence:  그러다가 1949년 6월 6일 이승만 대통령과 신성모 내무부 장관의 사주를 받은 친일 경찰이 반민특위 사무실을 습격하는 사건 발생 후 반민특위가 사실상 무력화되면서 서울 마포형무소에 구금되었던 하판락은 서울에서 3회, 부산에서 1회 등 모두 4차 공판을 거쳐 최종 무혐의로 풀려났다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 194만 관동군 신병, 신성모 등은 모두 구한말의 구국 영웅들이며, 이승만은 이들의 정적이었다.\n",
      "[2] : 이승9년 사후 이승만은 신성모, 윤보선 등과 함께 이승만의 암살 음모를 꾸몄다.\n",
      "[3] : 195만세대가 모여 신성모를 중심으로 이승만, 김구를 몰아내고 새로운 세대의 군주로 세웠다.\n",
      "[4] : 1947년 이승만은 신성모(成成謨)를 육군 대위로 임명하였다.\n",
      "[5] : 이승만과 신성모는 군정청 주임으로서 임시정부에 협조했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  바예지드 1세\n",
      "original obj   :  무라트 1세\n",
      "original label :  per:parents\n",
      "original sentence:  무라트 1세의 아들 바예지드 1세는 1396년에 불가리아 북부에서 니코폴리스 전투를 벌여, 이 전투에서 헝가리 왕국을 필두로 한 십자군을 격파, 오히려 영토를 더 크게 넓혔다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 무 무라트 1세의 아들 바예지드 1세가 1372년에 사망하면서 그의 아들 무르스텐이 국왕으로 즉위하였다.\n",
      "[2] : 바라라 공주 바예지드 1세(재위: 1848년 6월 22일 - 1929년 3월 9일)는 무라트 1세의 아들로 카스티야 왕국의 국왕(훗날의 왕위)을 맡고 있는 국공(직계)으로 추대되었다.\n",
      "[3] : 그러나라흐만이 바예지드 1세의 아들 무라트 1세에게 황제직을 물려주었고, 무샤바미아 왕조가 성립되었다.\n",
      "[4] : 바예지드 1세는 무라트 1세 때 처음으로 이슬람교를 받아들였으며, 이후로도 이슬람교 신자들은 무샤를 거쳐 마가렛에 흡수되었다.\n",
      "[5] : 무예지드 1세의 아들 무라트 1세는 카르만족을 정복하고, 카라얀의 통치권을 확보했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  박헌영\n",
      "original obj   :  조선로동당\n",
      "original label :  no_relation\n",
      "original sentence:  실제로 남한 쪽에서는 남조선로동당·근로인민당 등 좌익계열 정당뿐 아니라 한국독립당·민족자주연맹 등 우익계열 정당들도 참여하였을 뿐만 아니라, 박헌영·백남운·김구·김규식·조소앙 등 명망있는 좌익 및 우익 인사들도 참석했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 그러나 1949년 6월 25일에 조선로동당 제1서기로 임명되었으며, 1948년 7월 30일에 박헌영의 지시로 조선공산당과 국가기구가 동시에 부로 승인하였다.\n",
      "[2] : 박 조선로동당 제1차 대회에서 대당 선전부장 박헌영이 박규리에게 소련공산당 조직지도부 부장으로 승진시켜 주었다.\n",
      "[3] : 박 혁명당과 박헌영은 남로당원대회를 조선공산당, 북조선로동당(북조선)으로, 북으로 하여금 남조선으로 오게 하는 선에서 협상을 진행하고 있었다.\n",
      "[4] : 박 조선로동당 제1서기로 임명되었으며, 1946년 12월 박헌영에 의해 조선공산당 제2서기 직위 제대하였다.\n",
      "[5] : 1949년 12월에 박헌영이 죽자 조선로동당 정치국 상무위원에 임명되었다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  한국 프로야구\n",
      "original obj   :  KBO\n",
      "original label :  org:alternate_names\n",
      "original sentence:  1983년 한국 프로야구(KBO)의 삼미에 입단하면서 장명부라는 등록명을 사용했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 한국 프로야구단(KBO) 선수촌의 임시 코치로 선임됐다.\n",
      "[2] : 한국 프로야구단(KBO) 신인 드래프트에서 두산 베어스가 롯데 자이언츠를 상대로 KBO리그 역사상 첫 드라이트 드래곤즈에 등극했다.\n",
      "[3] : 김 11월은 한국 프로야구 KBO리그 연맹의 추천 선수로 지명돼 KBO) 이사회에서 추천된 투수였다.\n",
      "[4] : 한국 한국 프로야구(KBO)에서는 매년 10월을 야구 계수개발과 관련된 해로 정하고 있다.\n",
      "[5] : 그는에는 한국 프로야구(KBO) 선수 겸 지도자 연맹 총재 연임 신청을 포기하고, 한국 여자 야구 국가대표팀 감독으로 선임된 바 있다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  SK브로드밴드\n",
      "original obj   :  SK텔레콤\n",
      "original label :  org:member_of\n",
      "original sentence:  최남곤 유안타증권 연구원은 “지난달 30일 자로 과학기술정보통신부가 SK브로드밴드의 티브로드 M&A(인수·합병)에 대한 조건부 인가를 결정했다”라며 “SK텔레콤 입장에서는 향후 방통위 승인 이후 연결 범위 확대 효과를 얻게 될 전망”이라고 분석했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 유 “코로나19로 SK텔레콤의 미디어 콘텐츠가 결손되는 상황에서 미디어의 연결 자회사인 SK브로드밴드의 미디어 트래픽이 급감하고 있다. 이에 따라 미디어 분야에서는 SK C&C의 영향력 감소로 SKT 미디어 부문이 차지하는 비중이 약해질 수밖에 없다”라며 “이러한 현상의 원인은 SK그룹 내 미디어 계열사와의 통신사업 분리 이후, 미디어 플랫폼 사업부의 SK텔레그램 채널(Computee-Metal) 매출 급감으로 인한 미디어부문의 비용 증가에 따른 것으로 추정된다”고 분석했다.\n",
      "[2] : SK텔레콤 “SK텔레콤, SK브로드밴드, CJ헬로3호점 확보”\n",
      "[3] : SK “SK브로드밴드 자회사인 SK텔레콤 지분 49.37%는 자회사 티브이로 매각할 계획”이라며 “합병 완료 시 SK텔레콤의 지분율은 6.02%로 유지된다. 합병 완료 후 SK브로는 SK에 합병될 것”이라고 덧붙였다.\n",
      "[4] : SK텔레콤 “지난 1월, SK브로드밴은 지상파 방송 3사 중 가장 늦게 지상파 방송을 종료했다”며, “SK텔레콤은 올해 지상파 3사는 물론 유선방송도 종료했다. 이제 셋톱박스 시장도 포맷의 영향으로 소멸했다”고 지적했다.\n",
      "[5] : 그는 “SK텔레콤이 3사의 합병으로 SK브로드밴드와 SK커뮤니케이션즈가 합병하게 되면서, SK의 지배력이 약해졌다”며 “합병 이후, 셋톱박스(CMB) 사업부문은 SKC가 100% 지분을 보유하고 있기 때문에 SK텔레콤의 지분법손익은 1조원 수준”이라고 지적했다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  화순군\n",
      "original obj   :  구충곤\n",
      "original label :  org:top_members/employees\n",
      "original sentence:  화순군(군수 구충곤)이 신종 코로나바이러스 감염증(코로나19) 장기화로 어려움을 겪고 있는 지역 외식업소를 돕기 위해 ‘공직자 점심 나드리 day’를 운영한다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 화순군(군수 구충곤)이 지난 23일 화강면 소재 화춘지리 농가를 대상으로 농업기술센터 주관 교육을 실시했다.\n",
      "[2] : 화순군(군수 구충곤)이 신종 코로나바이러스 감염증(코로나의 초기 발견, 진단검사 등)으로 어려움을 겪고 있는 취약계층 아동과 청소년을 돕기 위한 ‘사랑의 김장 나눔 봉사’에 나섰다.\n",
      "[3] : 화순군(군수 구충곤)은 지난 19일 코로나19로 피해를 입은 취약계층 주민들을 위해 ‘희망의 손길’ 캠페인을 실시했다고 밝혔다.\n",
      "[4] : 화순군(군수 구충곤)은 코로나19 확산 방지를 위해 군민 누구나 다방면에 사용할 수 있는 생활용품을 구입할 수 있도록 지원한다.\n",
      "[5] : 화순군(군수 구충곤)은 지난 21일부터 22일까지 코로나19 특별방역대책본부(본부장 김도균)를 열고 군민에게 마스크를 나눠줬다고 밝혔다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  킴 리틀\n",
      "original obj   :  아스널\n",
      "original label :  per:employee_of\n",
      "original sentence:  시애틀 레인의 감독을 역임하고 있던 로라 하비는 킴 리틀의 시애틀 레인 이적을 주선했는데 로라 하비는 시애틀 레인의 감독으로 임명되기 1년 전까지 아스널의 감독을 맡았다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 아스널에서 활약하며 활약하던 동안, 그는 아스날 감독 킴 리틀을 상대로 \"절대 내겐 안 된다\"라고 말할 정도의 인내심을 가지게 만들었다.\n",
      "[2] : 널은 킴 리틀을 영입하면서 전 소속팀에서 뛰었던 박주영을 아스널로 이적시켰고 박주영도 아스날로 복귀시켰다.\n",
      "[3] : 널은 후반 17분 킴 리틀의 헤딩 골로 승점 1점을 얻었지만, 아스널의 리오넬 메시에게 통한의 동점골을 허용했다.\n",
      "[4] : 널은 킴 리틀이 아스널의 코르테스 센터백으로 활약한 바 있다.\n",
      "[5] : 그는킴 카이저, 로페스 레예스, 아담 램퍼드, 아스널 킴 리틀, 훌리오 사르첸첸, 호나우지뉴, 그리고 켄 로빈슨, 마하셔드 로저가 버티고 있다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "original sbj   :  아일랜드\n",
      "original obj   :  공화국\n",
      "original label :  org:political/religious_affiliation\n",
      "original sentence:  아일랜드 공화국은 1919년 1월 그레이트브리튼으로부터의 독립을 선언한 혁명정체다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "generated sentence\n",
      "[1] : 이 공화국의 군주들 중 하나인 토마시드 데 푸티넨은 1868년에 사망했으며, 이 해에 그는 아일랜드 공화국 군대의 총사령관 겸 총참모장으로 임명되었다.\n",
      "[2] : 아일랜드9년 6월 11일, 아일랜드 공화국은 소련의 패망에 따라 몰락했다.\n",
      "[3] : 아일랜드 공화국에서는 군대를 철수시켰으며, 아일랜드는 공화정청으로 편입되었다.\n",
      "[4] : 194 공화국에서는 아일랜드 공화국의 일부인 군주가 되어, 군대를 지휘하였다.\n",
      "[5] : 아일랜드 공화국의 수도였던 북아일랜드에서 태어난 영국인들은 아일랜드의 독립을 지지하였다.\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    origin = test_df.iloc[idx]\n",
    "    print('-'*100)\n",
    "    print('-'*100)\n",
    "    print('original sbj   : ', eval(origin['subject_entity'])['word'])\n",
    "    print('original obj   : ',eval(origin['object_entity'])['word'])\n",
    "    print('original label : ',origin['label'])\n",
    "    print('original sentence: ', origin['sentence'])\n",
    "    print('-'*100)\n",
    "    print('generated sentence')\n",
    "    for i in range(5):\n",
    "        print(f'[{i+1}] : {generated[idx][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nr3HyVqaB9uq",
    "outputId": "a070bea4-9da6-4c75-f2d3-04cb6a9e3e4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['홍길동(洪吉東, 1010년 ~ 1060년 11월 3일)은 1094년에서 고려말의 장군이자 문신으로 서기 1070년까지 종1품 대장부 겸 의병장인 겸 장군이었다.',\n",
       " '홍길동(洪吉東, 1010년 ~ 1048년)은 고려의 정치가이다.',\n",
       " '홍길동(洪吉東(柳吉李, 1010년 ~ 1043년 음력 12월)은 고려의 제4대 황제이며 호는 길동정(吉重大)이다.',\n",
       " '홍길동(洪吉東, 1010년 ~ 1073년)은 고려 말 조선 초기의 대표적인 장수로, 고려의 문신이자 정치가이다.',\n",
       " '홍길동(洪吉東, 1010년 - 1098년)은 고려 말기의 문신이다.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('홍길동', '1010년', 'per:date_of_birth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHrPAufKP-NN",
    "outputId": "86022939-4ab0-4c19-b557-32601d679e64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['홍길동(鴻吉東, 1853년 ~ 1903년)은 대한제국 군주인 윤치호, 순종의 서자였다.',\n",
       " '홍길동(洪吉東, 1853년 ~ 1912년 12월 18일)은 일제 강점기의 조선인, 독립운동가 겸 정치가이자 정치가이며, 대한제국 성립의 시초인 대한독립운동과 대한불교조계승상도 겸하고 있다.',\n",
       " '홍길동(洪吉東, 1881년 ~ 1853년)은 조선 말기의 관료 및 정치인이다.',\n",
       " '홍길동(洪吉東, 1853년 ~ 1926년 9월 29일)은 조선 말기의 무신이다.',\n",
       " '홍길동(洪吉東, 1853년 ~ 1938년 12월 14일)은 한국의 독립운동가다.']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('홍길동', '1853년', 'per:date_of_birth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-mRket_QMik",
    "outputId": "512aa1fa-e633-4a04-b411-983697cc4a71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010년 홍길동이 2010년 이후 무려 32년 만에 대표팀 감독으로 재영입 되었다.',\n",
       " \"한편, 2010년에 신인 발굴을 위해 발탁된 '홍길동'은 신인 지명된 첫 대상 선수가 됐다.\",\n",
       " '2010년에는 홍길동이 다시 MC로 돌아왔다.',\n",
       " '2010년 홍길동이 데뷔했는데 당시엔 홍길이동의 동생이었기 때문에 홍길을동이라는 가명을 사용했는데 이 가명은 그가 데뷔했을 당시 이미 쓰던 가명이 있었다고 한다.',\n",
       " '2010년부터 다시 황정민이 홍길동상을 수상했다.']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('홍길동', '2010년', 'per:date_of_birth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lRGu22EJQG6",
    "outputId": "df73002e-0b09-4449-ea02-c385fd24584a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이에 이명박 정부 출범 이후 첫 사업으로 추진된 4대강 사업은 그동안 이명박 정부에서 거의 전무한 사업으로 국토부 예산 305조원 투입과 각종 특혜, 특례 등 대규모 예산이 투입되는 등 사실상 무용론이 대두되고 있었다.',\n",
       " '이명박 정부는 특히 정부의 무리한 4대강사업 예산 편성·편성에 비판하며 4대강 사업의 국고투척으로 인한 국민의 혈세를 전액 국가금으로 환수하겠다는 대국민 약속을 지키겠다고 밝혔다.',\n",
       " '4대강 “4대강”과 관련해 노무현 전 대통령은 “노무현의 삶과 철학을 이어받은 사람이고 이명박의 정신을 이어받아 왔다”며 이명박 대통령의 사과를 촉구했다.',\n",
       " '이명박과 여당은 이를 묵살하고 4대강 사업, 부산지역 주요 관광지 및 문화 유산 등과 같은 굵직한 굵기 굵기의 굵기를 새단장해 새로운 관광 명소로 다시 탈환하려 했다.',\n",
       " '한편 이후 이명박의 측근이었던 김성주가 2007년 6월 14일에 친이명박 계열이 아닌 4대강추진본부 수석부지사를 지내면서 4대강 사업의 본질을 파악하고 4대강 사업을 직접 지시하는 등 정치적인 행보를 이어나갔다.']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('이명박', '4대강', 'per:product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8VdpS_gLpXG",
    "outputId": "94cfbe22-fc18-44ed-8f14-c3cf64ad8704"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['업스테이지(KLUE)는 영국 런던의 중심가 Barnestone Center for Live Arts와 필라델피아에서 출발하였으며 영국과 독일의 합작으로 설립되는 첫 번째 영국 록 밴드이다.',\n",
       " '업퍼티즈(KLUE, KOREA Chair, 이하 KNN)는 그룹 업스테이지의 여섯 번째 싱글 음반이다.',\n",
       " '업스테이지(KLUE)는 미국 미식축구 리그(MeFeat Calls)와 미국 아이스 댄스 그룹이다.',\n",
       " '《스테이지 KLUE》의 음악이론가 클라이언트 츠미르 클라인(The Claimi Clements)이 작업한 노래로 《Rock in the University》에서 사용된 업스테이지는 《Lucked Perfector》에 수록된 〈Technology〉의 OST로 \"크레멘\"을 리메이크하고 〈Lamenet〉로 인기를 모은 바 있다.',\n",
       " '스테이지(KLUE) 연습생은 현재 미국에 거주하고 있으며, 영국에서는 2017년 가을부터 활동을 시작했다.']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('업스테이지', 'KLUE', 'org:product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bI0k6sLlNVg-",
    "outputId": "ea4b0110-153d-41ad-a9b5-963db4a5b7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_relation': 9534, 'org:member_of': 1866, 'org:top_members/employees': 4284, 'org:alternate_names': 1320, 'per:date_of_birth': 1130, 'org:place_of_headquarters': 1195, 'per:employee_of': 3573, 'per:origin': 1234, 'per:title': 2103, 'org:members': 420, 'per:schools_attended': 82, 'per:colleagues': 534, 'per:alternate_names': 1001, 'per:spouse': 795, 'org:founded_by': 155, 'org:political/religious_affiliation': 98, 'per:children': 304, 'org:founded': 450, 'org:number_of_employees/members': 48, 'per:place_of_birth': 166, 'org:dissolved': 66, 'per:parents': 520, 'per:religion': 96, 'per:date_of_death': 418, 'per:place_of_residence': 193, 'per:other_family': 190, 'org:product': 380, 'per:siblings': 136, 'per:product': 139, 'per:place_of_death': 40}\n"
     ]
    }
   ],
   "source": [
    "print(rel_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "-C16Wet1R_U0"
   },
   "outputs": [],
   "source": [
    "sorted_rel_cnt = sorted(rel_cnt.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRDOp__-SOXO",
    "outputId": "e09c4245-af9e-4374-8029-63a6a5f07f17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no_relation', 9534),\n",
       " ('org:top_members/employees', 4284),\n",
       " ('per:employee_of', 3573),\n",
       " ('per:title', 2103),\n",
       " ('org:member_of', 1866),\n",
       " ('org:alternate_names', 1320),\n",
       " ('per:origin', 1234),\n",
       " ('org:place_of_headquarters', 1195),\n",
       " ('per:date_of_birth', 1130),\n",
       " ('per:alternate_names', 1001),\n",
       " ('per:spouse', 795),\n",
       " ('per:colleagues', 534),\n",
       " ('per:parents', 520),\n",
       " ('org:founded', 450),\n",
       " ('org:members', 420),\n",
       " ('per:date_of_death', 418),\n",
       " ('org:product', 380),\n",
       " ('per:children', 304),\n",
       " ('per:place_of_residence', 193),\n",
       " ('per:other_family', 190),\n",
       " ('per:place_of_birth', 166),\n",
       " ('org:founded_by', 155),\n",
       " ('per:product', 139),\n",
       " ('per:siblings', 136),\n",
       " ('org:political/religious_affiliation', 98),\n",
       " ('per:religion', 96),\n",
       " ('per:schools_attended', 82),\n",
       " ('org:dissolved', 66),\n",
       " ('org:number_of_employees/members', 48),\n",
       " ('per:place_of_death', 40)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_rel_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WE4l_CHSPJ3",
    "outputId": "46daf7fd-a86e-407d-b607-9ae8d181f5a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['그러나종친당은 홍길동 뿐만 아니라 활빈당 계열 인사들을 공천했는데, 홍건동 일파를 꺾지 못한다면 종친들에게 독이 될 것을 우려하여 홍익인 세력에게 염증을 느껴 참패를 한 사람들을 추방시키겠다는 것이었다.',\n",
       " '활길동이 이 당에 참여하였고, 그들과 함께 당과 함께 활빈당의 당수 홍길동을 두었고, 그는 당주 홍익표에 따라 홍의락에게 홍을표를 줄 것을 지시하였다.',\n",
       " '그러나 뒤이어 청나라에서 활빈당과 홍길동의 반탁활동을 적극 반대하였으며, 청 또한 이에 격파하고 나섰다.',\n",
       " '홍9년(1874년 1월 1일 ~ 1878년 1월 26일)은 홍길동의 부인으로, 활빈당(활빈당의 전신) 대표였다.',\n",
       " '김 활빈당은 홍길동이 재건사업(재건공사, 재건설사업)과 연계하여 홍씨 종의 활력 넘치는 사업들을 추진하였을 뿐만 아니라, 조선에 귀순한 독립운동가 겸 작가였던 송병서의 딸 홍건주의 아내 홍문교의 친정 오빠 홍경례와 숙모 홍재명사의 친형 홍정주 이씨의 친오빠 홍주상홍 홍판서를 두고, 홍사익의 조카인 홍용준 홍완중 등이 홍익당의 후신 홍찬주 이사장으로서 홍의주의 후신이 되어 조선시대를 관장하였다.']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sent('홍길동', '활빈당', 'per:place_of_death')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxSH7WCxTF-K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "RE_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05cc901eb29144fb8133980bae089c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c0ec53055a2469b9fcf292b95efa35b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d43e5280b154efdaeba463cb2568637": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19de366f3d1d44c5b6ed6dc6b540f92d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab4cde29b68b462eac058f64f0e85252",
      "placeholder": "​",
      "style": "IPY_MODEL_37a898f7fb064c74a166b6d26f50f428",
      "value": "Downloading: 100%"
     }
    },
    "20c98d696b7042b1a24a1b2c1f4bf211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2385694ce7a948018e64d0b1f0acc6ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2797c5056baf4d51be2ce0b52ddf3cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74be10b2598349d4ba8990ead111a8d2",
       "IPY_MODEL_e010526c062c41dfacbf4ce5003db6fa",
       "IPY_MODEL_3b777d2f2e76447ca1892b102c2f2ed0"
      ],
      "layout": "IPY_MODEL_3521a8f21b364bd893ee8add695855dd"
     }
    },
    "2ab3b9798b544567bad8729e3ec910e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b05ac62c5d541e09b639d84f9d7aac8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30767572fac94a08be6d7c48977c82da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d69e98c899d406ba03da142e7e0afd5",
      "placeholder": "​",
      "style": "IPY_MODEL_4e4bcd33151940cab613cac766376b8a",
      "value": "Downloading: 100%"
     }
    },
    "3521a8f21b364bd893ee8add695855dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37a898f7fb064c74a166b6d26f50f428": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a0d3b0b247b4a63bde1c2df3da6eed0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b777d2f2e76447ca1892b102c2f2ed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d890665d18c8480f9f49b61df290324b",
      "placeholder": "​",
      "style": "IPY_MODEL_c3f492b81f764181b7748d681b6f113f",
      "value": " 473M/473M [00:15&lt;00:00, 33.9MB/s]"
     }
    },
    "430462777a0e49b0bea32c226be263d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cbbdd0e7275465f84df0526f57f7369",
      "placeholder": "​",
      "style": "IPY_MODEL_67032db5adf743bfbf9eaac4bec04e30",
      "value": " 109/109 [00:00&lt;00:00, 2.64kB/s]"
     }
    },
    "461cadf6a25d446f99a5343ed8d003d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "462b8bc7aaf94708b5c27d70d7f8dd0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7af1817f3784b74b22a45248e829d05",
       "IPY_MODEL_fbca1e3743bb425aa62d12fff9fcabe4",
       "IPY_MODEL_b6016bf27a55486e8d974ed3fa5e14b7"
      ],
      "layout": "IPY_MODEL_3a0d3b0b247b4a63bde1c2df3da6eed0"
     }
    },
    "4e4bcd33151940cab613cac766376b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "514fee3580674299b60dfd946aec7c53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9e09866a50e421e8af4c939b3a47ac0",
      "placeholder": "​",
      "style": "IPY_MODEL_d40fa5156e4345f4ac7119df8fd913ec",
      "value": " 2.00/2.00 [00:00&lt;00:00, 45.9B/s]"
     }
    },
    "57f3ece2a95348d5b4bb613d55439834": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a4263adffbd44b3b77699bf8a548095": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b9d82a43440434bb176799b8352d676": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ec94aa5826a4abaaecaa05a2cd60789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "625118e6e10141569629d027824a1252": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63fae3b4dd434bb6b82006c4bc029a87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "641e7a7c7eb54a8cb48709ac3408d4d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6523bac8e25d454098a534249415052f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f2649e4a9c64dfab27cd7b9f569ac54",
      "placeholder": "​",
      "style": "IPY_MODEL_5ec94aa5826a4abaaecaa05a2cd60789",
      "value": "Downloading: 100%"
     }
    },
    "67032db5adf743bfbf9eaac4bec04e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d69e98c899d406ba03da142e7e0afd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e063852835d4a9389f2bd36a58c430c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71594b180cfe49048b7caabb753c69a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "730b2ac11efc43dfa1a6fbcd01ad6df9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30767572fac94a08be6d7c48977c82da",
       "IPY_MODEL_be736850565142d4b3dbc01f2f4a80ec",
       "IPY_MODEL_a1ee0824323b4650ac62ac198057e946"
      ],
      "layout": "IPY_MODEL_71594b180cfe49048b7caabb753c69a9"
     }
    },
    "74be10b2598349d4ba8990ead111a8d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e063852835d4a9389f2bd36a58c430c",
      "placeholder": "​",
      "style": "IPY_MODEL_f8edd91437384be5a7d29365d068bea2",
      "value": "Downloading: 100%"
     }
    },
    "8354c2f5ad4c4c91b08e1eaf8e958e75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b05ac62c5d541e09b639d84f9d7aac8",
      "placeholder": "​",
      "style": "IPY_MODEL_0d43e5280b154efdaeba463cb2568637",
      "value": "Downloading: 100%"
     }
    },
    "83ed8209b19f435a9a87f4bd26ba8985": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f2649e4a9c64dfab27cd7b9f569ac54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a7569ba6614a5b960d6c70165ed086": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98164fdbde1b47a1a0a69a7b32700988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b4abd7a19b1431fb0e0fffbedf76853",
      "max": 109,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd2298e0ab2a4f24adb2e52b61b39abf",
      "value": 109
     }
    },
    "9b4abd7a19b1431fb0e0fffbedf76853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cbbdd0e7275465f84df0526f57f7369": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1ee0824323b4650ac62ac198057e946": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ab3b9798b544567bad8729e3ec910e7",
      "placeholder": "​",
      "style": "IPY_MODEL_d35d6309c2804d5ebef94fbc894c7b06",
      "value": " 1.08k/1.08k [00:00&lt;00:00, 22.8kB/s]"
     }
    },
    "a56df1ea2dc24097849483468682b52d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19de366f3d1d44c5b6ed6dc6b540f92d",
       "IPY_MODEL_b8b844540ff646758dc9c1339012919c",
       "IPY_MODEL_b1c5f3add0dc40e48f7eeff75644bdf2"
      ],
      "layout": "IPY_MODEL_d37e3c1f9ee949c7a5f97c0722375e7d"
     }
    },
    "a7af1817f3784b74b22a45248e829d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b9d82a43440434bb176799b8352d676",
      "placeholder": "​",
      "style": "IPY_MODEL_83ed8209b19f435a9a87f4bd26ba8985",
      "value": "Downloading: 100%"
     }
    },
    "aa766e3cca724ac7b03c7eb7a9f1469f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6523bac8e25d454098a534249415052f",
       "IPY_MODEL_da1f448798154db3a8b9f2797695c634",
       "IPY_MODEL_514fee3580674299b60dfd946aec7c53"
      ],
      "layout": "IPY_MODEL_57f3ece2a95348d5b4bb613d55439834"
     }
    },
    "ab4cde29b68b462eac058f64f0e85252": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1c5f3add0dc40e48f7eeff75644bdf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20c98d696b7042b1a24a1b2c1f4bf211",
      "placeholder": "​",
      "style": "IPY_MODEL_05cc901eb29144fb8133980bae089c69",
      "value": " 666k/666k [00:00&lt;00:00, 648kB/s]"
     }
    },
    "b4a5b14f095e4b0d8287a3e96a73fce9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8354c2f5ad4c4c91b08e1eaf8e958e75",
       "IPY_MODEL_98164fdbde1b47a1a0a69a7b32700988",
       "IPY_MODEL_430462777a0e49b0bea32c226be263d0"
      ],
      "layout": "IPY_MODEL_641e7a7c7eb54a8cb48709ac3408d4d6"
     }
    },
    "b6016bf27a55486e8d974ed3fa5e14b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e64ca505b3994c6981cd6c2575d00e89",
      "placeholder": "​",
      "style": "IPY_MODEL_63fae3b4dd434bb6b82006c4bc029a87",
      "value": " 85.0/85.0 [00:00&lt;00:00, 2.02kB/s]"
     }
    },
    "b8b844540ff646758dc9c1339012919c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2385694ce7a948018e64d0b1f0acc6ce",
      "max": 682149,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_625118e6e10141569629d027824a1252",
      "value": 682149
     }
    },
    "bd2298e0ab2a4f24adb2e52b61b39abf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be736850565142d4b3dbc01f2f4a80ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e98d02dd6de448439968524f9052b1bf",
      "max": 1110,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_461cadf6a25d446f99a5343ed8d003d9",
      "value": 1110
     }
    },
    "c3f492b81f764181b7748d681b6f113f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d35d6309c2804d5ebef94fbc894c7b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d37e3c1f9ee949c7a5f97c0722375e7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d40fa5156e4345f4ac7119df8fd913ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d890665d18c8480f9f49b61df290324b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9e09866a50e421e8af4c939b3a47ac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da1f448798154db3a8b9f2797695c634": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e28b532367fa4652a6d9152bfac114cc",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a4263adffbd44b3b77699bf8a548095",
      "value": 2
     }
    },
    "e010526c062c41dfacbf4ce5003db6fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8386756ec514b379a2b571dc2e40be7",
      "max": 495536138,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91a7569ba6614a5b960d6c70165ed086",
      "value": 495536138
     }
    },
    "e28b532367fa4652a6d9152bfac114cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e64ca505b3994c6981cd6c2575d00e89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e98d02dd6de448439968524f9052b1bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f747f5533bce4ba2b4b643ef7158b7ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8386756ec514b379a2b571dc2e40be7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8edd91437384be5a7d29365d068bea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbca1e3743bb425aa62d12fff9fcabe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c0ec53055a2469b9fcf292b95efa35b",
      "max": 85,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f747f5533bce4ba2b4b643ef7158b7ee",
      "value": 85
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}